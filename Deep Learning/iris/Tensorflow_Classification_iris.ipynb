{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sinisha/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/sinisha/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/sinisha/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/sinisha/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/sinisha/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tensorflow import constant\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow import feature_column \n",
    "from tensorflow import estimator\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.kerasras.utils import plot_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(df.drop('species',axis=1))\n",
    "Y = np.array(df['species'])\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Le = LabelEncoder()\n",
    "Le.fit(['setosa', 'virginica', 'versicolor'])\n",
    "Y_new = Le.transform(Y)\n",
    "Y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_new, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "84/84 [==============================] - 2s 22ms/sample - loss: 1.4833 - accuracy: 0.5357 - val_loss: 1.2876 - val_accuracy: 0.5714\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 0s 733us/sample - loss: 1.6456 - accuracy: 0.4048 - val_loss: 0.9938 - val_accuracy: 0.5714\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 0s 690us/sample - loss: 1.1294 - accuracy: 0.4762 - val_loss: 0.9348 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 0s 797us/sample - loss: 1.1005 - accuracy: 0.5000 - val_loss: 0.9012 - val_accuracy: 0.5714\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 0s 917us/sample - loss: 1.2084 - accuracy: 0.4643 - val_loss: 0.8607 - val_accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 0s 662us/sample - loss: 0.9952 - accuracy: 0.5476 - val_loss: 0.8381 - val_accuracy: 0.5714\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 0s 676us/sample - loss: 0.9544 - accuracy: 0.5952 - val_loss: 0.8128 - val_accuracy: 0.5714\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 0s 722us/sample - loss: 0.8843 - accuracy: 0.5238 - val_loss: 0.7820 - val_accuracy: 0.5714\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 0s 835us/sample - loss: 0.7705 - accuracy: 0.6786 - val_loss: 0.7396 - val_accuracy: 0.5714\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 0s 706us/sample - loss: 0.7542 - accuracy: 0.6905 - val_loss: 0.7186 - val_accuracy: 0.5714\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 0s 647us/sample - loss: 0.7027 - accuracy: 0.6548 - val_loss: 0.7115 - val_accuracy: 0.5714\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 0s 623us/sample - loss: 0.7199 - accuracy: 0.7024 - val_loss: 0.6973 - val_accuracy: 0.5714\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 0s 681us/sample - loss: 0.7302 - accuracy: 0.6905 - val_loss: 0.6788 - val_accuracy: 0.5714\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 0s 689us/sample - loss: 0.7023 - accuracy: 0.6905 - val_loss: 0.6548 - val_accuracy: 0.5714\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 0s 822us/sample - loss: 0.6283 - accuracy: 0.7143 - val_loss: 0.6434 - val_accuracy: 0.5714\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 0s 798us/sample - loss: 0.6193 - accuracy: 0.7262 - val_loss: 0.6254 - val_accuracy: 0.5714\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 0s 831us/sample - loss: 0.5739 - accuracy: 0.7381 - val_loss: 0.6075 - val_accuracy: 0.6190\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 0s 861us/sample - loss: 0.6240 - accuracy: 0.7024 - val_loss: 0.6060 - val_accuracy: 0.5714\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 0s 735us/sample - loss: 0.6195 - accuracy: 0.6905 - val_loss: 0.5907 - val_accuracy: 0.6190\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 0s 643us/sample - loss: 0.6044 - accuracy: 0.7500 - val_loss: 0.5876 - val_accuracy: 0.5714\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 0s 648us/sample - loss: 0.6174 - accuracy: 0.7619 - val_loss: 0.5857 - val_accuracy: 0.5714\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 0s 718us/sample - loss: 0.5930 - accuracy: 0.6786 - val_loss: 0.5782 - val_accuracy: 0.5714\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 0s 653us/sample - loss: 0.5432 - accuracy: 0.7619 - val_loss: 0.5787 - val_accuracy: 0.5714\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 0s 639us/sample - loss: 0.5528 - accuracy: 0.7738 - val_loss: 0.5711 - val_accuracy: 0.5714\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 0s 618us/sample - loss: 0.5507 - accuracy: 0.7262 - val_loss: 0.5875 - val_accuracy: 0.5714\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 0s 657us/sample - loss: 0.5898 - accuracy: 0.7143 - val_loss: 0.5674 - val_accuracy: 0.5714\n",
      "Epoch 27/100\n",
      "84/84 [==============================] - 0s 976us/sample - loss: 0.4920 - accuracy: 0.7381 - val_loss: 0.5508 - val_accuracy: 0.6667\n",
      "Epoch 28/100\n",
      "84/84 [==============================] - 0s 962us/sample - loss: 0.4495 - accuracy: 0.8095 - val_loss: 0.5517 - val_accuracy: 0.5714\n",
      "Epoch 29/100\n",
      "84/84 [==============================] - 0s 820us/sample - loss: 0.4768 - accuracy: 0.8214 - val_loss: 0.5449 - val_accuracy: 0.6190\n",
      "Epoch 30/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4599 - accuracy: 0.7738 - val_loss: 0.5414 - val_accuracy: 0.6190\n",
      "Epoch 31/100\n",
      "84/84 [==============================] - 0s 711us/sample - loss: 0.4686 - accuracy: 0.7500 - val_loss: 0.5198 - val_accuracy: 0.6667\n",
      "Epoch 32/100\n",
      "84/84 [==============================] - 0s 571us/sample - loss: 0.4161 - accuracy: 0.8095 - val_loss: 0.5587 - val_accuracy: 0.5714\n",
      "Epoch 33/100\n",
      "84/84 [==============================] - 0s 565us/sample - loss: 0.4765 - accuracy: 0.7857 - val_loss: 0.5355 - val_accuracy: 0.6190\n",
      "Epoch 34/100\n",
      "84/84 [==============================] - 0s 809us/sample - loss: 0.3878 - accuracy: 0.7976 - val_loss: 0.5071 - val_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "84/84 [==============================] - 0s 783us/sample - loss: 0.4365 - accuracy: 0.7738 - val_loss: 0.4919 - val_accuracy: 0.7143\n",
      "Epoch 36/100\n",
      "84/84 [==============================] - 0s 701us/sample - loss: 0.4555 - accuracy: 0.7857 - val_loss: 0.4774 - val_accuracy: 0.7143\n",
      "Epoch 37/100\n",
      "84/84 [==============================] - 0s 814us/sample - loss: 0.4068 - accuracy: 0.8452 - val_loss: 0.4594 - val_accuracy: 0.8571\n",
      "Epoch 38/100\n",
      "84/84 [==============================] - 0s 822us/sample - loss: 0.4196 - accuracy: 0.8333 - val_loss: 0.4603 - val_accuracy: 0.7619\n",
      "Epoch 39/100\n",
      "84/84 [==============================] - 0s 529us/sample - loss: 0.4997 - accuracy: 0.7143 - val_loss: 0.4548 - val_accuracy: 0.8095\n",
      "Epoch 40/100\n",
      "84/84 [==============================] - 0s 521us/sample - loss: 0.4163 - accuracy: 0.8095 - val_loss: 0.4677 - val_accuracy: 0.7143\n",
      "Epoch 41/100\n",
      "84/84 [==============================] - 0s 515us/sample - loss: 0.3611 - accuracy: 0.8452 - val_loss: 0.4569 - val_accuracy: 0.8095\n",
      "Epoch 42/100\n",
      "84/84 [==============================] - 0s 601us/sample - loss: 0.4318 - accuracy: 0.8095 - val_loss: 0.4722 - val_accuracy: 0.7143\n",
      "Epoch 43/100\n",
      "84/84 [==============================] - 0s 768us/sample - loss: 0.4222 - accuracy: 0.7857 - val_loss: 0.4381 - val_accuracy: 0.8095\n",
      "Epoch 44/100\n",
      "84/84 [==============================] - 0s 855us/sample - loss: 0.3720 - accuracy: 0.8810 - val_loss: 0.4560 - val_accuracy: 0.7143\n",
      "Epoch 45/100\n",
      "84/84 [==============================] - 0s 697us/sample - loss: 0.3353 - accuracy: 0.8333 - val_loss: 0.4281 - val_accuracy: 0.8095\n",
      "Epoch 46/100\n",
      "84/84 [==============================] - 0s 563us/sample - loss: 0.3938 - accuracy: 0.8095 - val_loss: 0.4550 - val_accuracy: 0.7143\n",
      "Epoch 47/100\n",
      "84/84 [==============================] - 0s 551us/sample - loss: 0.4680 - accuracy: 0.7619 - val_loss: 0.4068 - val_accuracy: 0.8571\n",
      "Epoch 48/100\n",
      "84/84 [==============================] - 0s 507us/sample - loss: 0.3972 - accuracy: 0.8214 - val_loss: 0.4040 - val_accuracy: 0.8571\n",
      "Epoch 49/100\n",
      "84/84 [==============================] - 0s 506us/sample - loss: 0.3293 - accuracy: 0.8929 - val_loss: 0.4474 - val_accuracy: 0.7143\n",
      "Epoch 50/100\n",
      "84/84 [==============================] - 0s 605us/sample - loss: 0.3390 - accuracy: 0.8452 - val_loss: 0.4337 - val_accuracy: 0.7619\n",
      "Epoch 51/100\n",
      "84/84 [==============================] - 0s 494us/sample - loss: 0.3909 - accuracy: 0.7976 - val_loss: 0.3950 - val_accuracy: 0.8571\n",
      "Epoch 52/100\n",
      "84/84 [==============================] - 0s 579us/sample - loss: 0.3035 - accuracy: 0.8571 - val_loss: 0.3787 - val_accuracy: 0.8571\n",
      "Epoch 53/100\n",
      "84/84 [==============================] - 0s 525us/sample - loss: 0.3320 - accuracy: 0.8452 - val_loss: 0.3861 - val_accuracy: 0.8571\n",
      "Epoch 54/100\n",
      "84/84 [==============================] - 0s 469us/sample - loss: 0.2677 - accuracy: 0.9048 - val_loss: 0.3628 - val_accuracy: 0.8571\n",
      "Epoch 55/100\n",
      "84/84 [==============================] - 0s 571us/sample - loss: 0.3398 - accuracy: 0.8214 - val_loss: 0.3584 - val_accuracy: 0.8571\n",
      "Epoch 56/100\n",
      "84/84 [==============================] - 0s 511us/sample - loss: 0.3657 - accuracy: 0.8333 - val_loss: 0.3644 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "84/84 [==============================] - 0s 513us/sample - loss: 0.3565 - accuracy: 0.8214 - val_loss: 0.3572 - val_accuracy: 0.8571\n",
      "Epoch 58/100\n",
      "84/84 [==============================] - 0s 496us/sample - loss: 0.3100 - accuracy: 0.8095 - val_loss: 0.3636 - val_accuracy: 0.8571\n",
      "Epoch 59/100\n",
      "84/84 [==============================] - 0s 486us/sample - loss: 0.2874 - accuracy: 0.9048 - val_loss: 0.3537 - val_accuracy: 0.8571\n",
      "Epoch 60/100\n",
      "84/84 [==============================] - 0s 532us/sample - loss: 0.3851 - accuracy: 0.7857 - val_loss: 0.3946 - val_accuracy: 0.8095\n",
      "Epoch 61/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3341 - accuracy: 0.8929 - val_loss: 0.3313 - val_accuracy: 0.8571\n",
      "Epoch 62/100\n",
      "84/84 [==============================] - 0s 869us/sample - loss: 0.2943 - accuracy: 0.8810 - val_loss: 0.3247 - val_accuracy: 0.8571\n",
      "Epoch 63/100\n",
      "84/84 [==============================] - 0s 645us/sample - loss: 0.3079 - accuracy: 0.8810 - val_loss: 0.3305 - val_accuracy: 0.8571\n",
      "Epoch 64/100\n",
      "84/84 [==============================] - 0s 524us/sample - loss: 0.3658 - accuracy: 0.8452 - val_loss: 0.3517 - val_accuracy: 0.8571\n",
      "Epoch 65/100\n",
      "84/84 [==============================] - 0s 513us/sample - loss: 0.3073 - accuracy: 0.8333 - val_loss: 0.3296 - val_accuracy: 0.8571\n",
      "Epoch 66/100\n",
      "84/84 [==============================] - 0s 537us/sample - loss: 0.2800 - accuracy: 0.8810 - val_loss: 0.2911 - val_accuracy: 0.9524\n",
      "Epoch 67/100\n",
      "84/84 [==============================] - 0s 525us/sample - loss: 0.2549 - accuracy: 0.9048 - val_loss: 0.2806 - val_accuracy: 0.9524\n",
      "Epoch 68/100\n",
      "84/84 [==============================] - 0s 949us/sample - loss: 0.2796 - accuracy: 0.9048 - val_loss: 0.2910 - val_accuracy: 0.9524\n",
      "Epoch 69/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2223 - accuracy: 0.9048 - val_loss: 0.3014 - val_accuracy: 0.8571\n",
      "Epoch 70/100\n",
      "84/84 [==============================] - 0s 705us/sample - loss: 0.2679 - accuracy: 0.8810 - val_loss: 0.2863 - val_accuracy: 0.9048\n",
      "Epoch 71/100\n",
      "84/84 [==============================] - 0s 539us/sample - loss: 0.3130 - accuracy: 0.9048 - val_loss: 0.2814 - val_accuracy: 0.9524\n",
      "Epoch 72/100\n",
      "84/84 [==============================] - 0s 523us/sample - loss: 0.2663 - accuracy: 0.9286 - val_loss: 0.2883 - val_accuracy: 0.8571\n",
      "Epoch 73/100\n",
      "84/84 [==============================] - 0s 538us/sample - loss: 0.3023 - accuracy: 0.8810 - val_loss: 0.2764 - val_accuracy: 0.8571\n",
      "Epoch 74/100\n",
      "84/84 [==============================] - 0s 533us/sample - loss: 0.2187 - accuracy: 0.9405 - val_loss: 0.2627 - val_accuracy: 0.9524\n",
      "Epoch 75/100\n",
      "84/84 [==============================] - 0s 519us/sample - loss: 0.2227 - accuracy: 0.9048 - val_loss: 0.2493 - val_accuracy: 0.9048\n",
      "Epoch 76/100\n",
      "84/84 [==============================] - 0s 526us/sample - loss: 0.3070 - accuracy: 0.9167 - val_loss: 0.2636 - val_accuracy: 0.9524\n",
      "Epoch 77/100\n",
      "84/84 [==============================] - 0s 539us/sample - loss: 0.2162 - accuracy: 0.9405 - val_loss: 0.2705 - val_accuracy: 0.9048\n",
      "Epoch 78/100\n",
      "84/84 [==============================] - 0s 529us/sample - loss: 0.2434 - accuracy: 0.9167 - val_loss: 0.2526 - val_accuracy: 0.9524\n",
      "Epoch 79/100\n",
      "84/84 [==============================] - 0s 538us/sample - loss: 0.2418 - accuracy: 0.8929 - val_loss: 0.2499 - val_accuracy: 0.9524\n",
      "Epoch 80/100\n",
      "84/84 [==============================] - 0s 552us/sample - loss: 0.2397 - accuracy: 0.8452 - val_loss: 0.2738 - val_accuracy: 0.8571\n",
      "Epoch 81/100\n",
      "84/84 [==============================] - 0s 533us/sample - loss: 0.2275 - accuracy: 0.9048 - val_loss: 0.2631 - val_accuracy: 0.8571\n",
      "Epoch 82/100\n",
      "84/84 [==============================] - 0s 524us/sample - loss: 0.1920 - accuracy: 0.9286 - val_loss: 0.2367 - val_accuracy: 0.9524\n",
      "Epoch 83/100\n",
      "84/84 [==============================] - 0s 478us/sample - loss: 0.2648 - accuracy: 0.8929 - val_loss: 0.2469 - val_accuracy: 0.9524\n",
      "Epoch 84/100\n",
      "84/84 [==============================] - 0s 500us/sample - loss: 0.2383 - accuracy: 0.8929 - val_loss: 0.2787 - val_accuracy: 0.8571\n",
      "Epoch 85/100\n",
      "84/84 [==============================] - 0s 531us/sample - loss: 0.2091 - accuracy: 0.9286 - val_loss: 0.2303 - val_accuracy: 0.9048\n",
      "Epoch 86/100\n",
      "84/84 [==============================] - 0s 526us/sample - loss: 0.2134 - accuracy: 0.8929 - val_loss: 0.2371 - val_accuracy: 0.9524\n",
      "Epoch 87/100\n",
      "84/84 [==============================] - 0s 497us/sample - loss: 0.2604 - accuracy: 0.8690 - val_loss: 0.3187 - val_accuracy: 0.8571\n",
      "Epoch 88/100\n",
      "84/84 [==============================] - 0s 490us/sample - loss: 0.2069 - accuracy: 0.9167 - val_loss: 0.2238 - val_accuracy: 0.9524\n",
      "Epoch 89/100\n",
      "84/84 [==============================] - 0s 810us/sample - loss: 0.2120 - accuracy: 0.9048 - val_loss: 0.2253 - val_accuracy: 0.9524\n",
      "Epoch 90/100\n",
      "84/84 [==============================] - 0s 934us/sample - loss: 0.2420 - accuracy: 0.8690 - val_loss: 0.2170 - val_accuracy: 0.9048\n",
      "Epoch 91/100\n",
      "84/84 [==============================] - 0s 801us/sample - loss: 0.2637 - accuracy: 0.8452 - val_loss: 0.2322 - val_accuracy: 0.9524\n",
      "Epoch 92/100\n",
      "84/84 [==============================] - 0s 672us/sample - loss: 0.2537 - accuracy: 0.8690 - val_loss: 0.2423 - val_accuracy: 0.9048\n",
      "Epoch 93/100\n",
      "84/84 [==============================] - 0s 524us/sample - loss: 0.2431 - accuracy: 0.9048 - val_loss: 0.2246 - val_accuracy: 0.9524\n",
      "Epoch 94/100\n",
      "84/84 [==============================] - 0s 533us/sample - loss: 0.3229 - accuracy: 0.8333 - val_loss: 0.2644 - val_accuracy: 0.8571\n",
      "Epoch 95/100\n",
      "84/84 [==============================] - 0s 574us/sample - loss: 0.1911 - accuracy: 0.9167 - val_loss: 0.2488 - val_accuracy: 0.9048\n",
      "Epoch 96/100\n",
      "84/84 [==============================] - 0s 525us/sample - loss: 0.2117 - accuracy: 0.9167 - val_loss: 0.2294 - val_accuracy: 0.9524\n",
      "Epoch 97/100\n",
      "84/84 [==============================] - 0s 565us/sample - loss: 0.1991 - accuracy: 0.9405 - val_loss: 0.2423 - val_accuracy: 0.9048\n",
      "Epoch 98/100\n",
      "84/84 [==============================] - 0s 661us/sample - loss: 0.1665 - accuracy: 0.9286 - val_loss: 0.2476 - val_accuracy: 0.9048\n",
      "Epoch 99/100\n",
      "84/84 [==============================] - 0s 832us/sample - loss: 0.1967 - accuracy: 0.9048 - val_loss: 0.2127 - val_accuracy: 0.9524\n",
      "Epoch 100/100\n",
      "84/84 [==============================] - 0s 844us/sample - loss: 0.2113 - accuracy: 0.9405 - val_loss: 0.2884 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda905030f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_keras = Sequential()\n",
    "\n",
    "# Define the first layer\n",
    "model_keras.add(keras.layers.Dense(36, activation='relu', input_shape = (4,)))\n",
    "model_keras.add(keras.layers.Dropout(0.2))\n",
    "# Add activation function to classifier\n",
    "model_keras.add(keras.layers.Dense(18, activation='relu'))\n",
    "model_keras.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model_keras.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "# Finish the model compilation\n",
    "model_keras.compile(optimizer=keras.optimizers.Adam(lr=0.001), \n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# Complete the model fit operation\n",
    "model_keras.fit(X_train, Y_train, epochs=100, batch_size=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 1, 2, 2, 1, 2, 0, 2, 0, 0, 2, 2, 1, 1, 1, 0, 2, 1, 0,\n",
       "       1, 1, 1, 1, 1, 2, 0, 0, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 0, 0, 0, 1,\n",
       "       1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.array(model_keras.predict_classes(X_test))\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'setosa', 'setosa', 'virginica', 'versicolor',\n",
       "       'virginica', 'virginica', 'versicolor', 'virginica', 'setosa',\n",
       "       'virginica', 'setosa', 'setosa', 'virginica', 'virginica',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'setosa', 'virginica',\n",
       "       'versicolor', 'setosa', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'virginica', 'setosa', 'setosa',\n",
       "       'virginica', 'versicolor', 'virginica', 'versicolor', 'virginica',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'virginica', 'setosa', 'setosa', 'setosa', 'versicolor',\n",
       "       'versicolor'], dtype='<U10')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_predictions = Le.inverse_transform(predictions)\n",
    "new_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species      setosa  versicolor  virginica\n",
      "predictions                               \n",
      "setosa           13           0          0\n",
      "versicolor        0          19          0\n",
      "virginica         0           1         12\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.DataFrame({'predictions': new_predictions, 'species': Le.inverse_transform(Y_test)})\n",
    "\n",
    "# Create crosstab: ct\n",
    "ct3 = pd.crosstab(df3['predictions'], df3['species'])\n",
    "print(ct3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 0, 1, 1, 0, 2, 0, 1, 2, 1, 0, 0, 1, 0, 1, 2, 2, 2, 0, 1,\n",
       "       0, 2, 2, 1, 2, 1, 2, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2,\n",
       "       2, 2, 0, 1, 2, 0, 0, 2, 2, 0, 1, 0, 2, 2, 0, 2, 1, 1, 2, 0, 2, 0,\n",
       "       1, 2, 0, 1, 0, 2, 1, 2, 0, 2, 2, 2, 1, 0, 0, 2, 2, 0, 1, 2, 2, 2,\n",
       "       2, 0, 2, 0, 2, 1, 2, 2, 0, 2, 1, 1, 1, 2, 1, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.array(model_keras.predict_classes(X_train))\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'virginica', 'versicolor', 'setosa', 'versicolor',\n",
       "       'versicolor', 'setosa', 'virginica', 'setosa', 'versicolor',\n",
       "       'virginica', 'versicolor', 'setosa', 'setosa', 'versicolor',\n",
       "       'setosa', 'versicolor', 'virginica', 'virginica', 'virginica',\n",
       "       'setosa', 'versicolor', 'setosa', 'virginica', 'virginica',\n",
       "       'versicolor', 'virginica', 'versicolor', 'virginica', 'setosa',\n",
       "       'setosa', 'setosa', 'versicolor', 'setosa', 'setosa', 'setosa',\n",
       "       'virginica', 'setosa', 'setosa', 'virginica', 'virginica',\n",
       "       'setosa', 'setosa', 'virginica', 'virginica', 'virginica',\n",
       "       'setosa', 'versicolor', 'virginica', 'setosa', 'setosa',\n",
       "       'virginica', 'virginica', 'setosa', 'versicolor', 'setosa',\n",
       "       'virginica', 'virginica', 'setosa', 'virginica', 'versicolor',\n",
       "       'versicolor', 'virginica', 'setosa', 'virginica', 'setosa',\n",
       "       'versicolor', 'virginica', 'setosa', 'versicolor', 'setosa',\n",
       "       'virginica', 'versicolor', 'virginica', 'setosa', 'virginica',\n",
       "       'virginica', 'virginica', 'versicolor', 'setosa', 'setosa',\n",
       "       'virginica', 'virginica', 'setosa', 'versicolor', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'setosa', 'virginica',\n",
       "       'setosa', 'virginica', 'versicolor', 'virginica', 'virginica',\n",
       "       'setosa', 'virginica', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'virginica', 'versicolor', 'setosa', 'versicolor'], dtype='<U10')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_predictions = Le.inverse_transform(predictions)\n",
    "new_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species      setosa  versicolor  virginica\n",
      "predictions                               \n",
      "setosa           37           0          0\n",
      "versicolor        0          26          0\n",
      "virginica         0           4         38\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.DataFrame({'predictions': new_predictions, 'species': Le.inverse_transform(Y_train)})\n",
    "\n",
    "# Create crosstab: ct\n",
    "ct3 = pd.crosstab(df3['predictions'], df3['species'])\n",
    "print(ct3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Le = LabelEncoder()\n",
    "Le.fit(['setosa', 'virginica', 'versicolor'])\n",
    "Y_new = Le.transform(Y)\n",
    "Y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_new, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_cat = to_categorical(Y_train)\n",
    "Y_test_cat = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "84/84 [==============================] - 2s 18ms/sample - loss: 2.0503 - accuracy: 0.2976 - val_loss: 0.9608 - val_accuracy: 0.5714\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 1.3844 - accuracy: 0.4405 - val_loss: 0.9284 - val_accuracy: 0.5714\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 1.3837 - accuracy: 0.3929 - val_loss: 0.9007 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 1.2924 - accuracy: 0.3690 - val_loss: 0.8737 - val_accuracy: 0.5714\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.9957 - accuracy: 0.4524 - val_loss: 0.8639 - val_accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 1.1834 - accuracy: 0.3810 - val_loss: 0.8582 - val_accuracy: 0.5714\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.9918 - accuracy: 0.5357 - val_loss: 0.8687 - val_accuracy: 0.5714\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.8698 - accuracy: 0.5952 - val_loss: 0.8773 - val_accuracy: 0.5714\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.9184 - accuracy: 0.5714 - val_loss: 0.8631 - val_accuracy: 0.5714\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.8880 - accuracy: 0.5714 - val_loss: 0.8399 - val_accuracy: 0.5714\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.9009 - accuracy: 0.5714 - val_loss: 0.8222 - val_accuracy: 0.5714\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.7563 - accuracy: 0.6429 - val_loss: 0.7971 - val_accuracy: 0.5714\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.7439 - accuracy: 0.6786 - val_loss: 0.7767 - val_accuracy: 0.5714\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.8353 - accuracy: 0.5833 - val_loss: 0.7632 - val_accuracy: 0.5714\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.7540 - accuracy: 0.6905 - val_loss: 0.7419 - val_accuracy: 0.5714\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.6539 - accuracy: 0.6667 - val_loss: 0.7223 - val_accuracy: 0.5714\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.7726 - accuracy: 0.6190 - val_loss: 0.7021 - val_accuracy: 0.5714\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.7977 - accuracy: 0.5833 - val_loss: 0.6832 - val_accuracy: 0.6190\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.7018 - accuracy: 0.6190 - val_loss: 0.6724 - val_accuracy: 0.5714\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.6175 - accuracy: 0.7143 - val_loss: 0.6702 - val_accuracy: 0.5714\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.6428 - accuracy: 0.6905 - val_loss: 0.6583 - val_accuracy: 0.5714\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.6853 - accuracy: 0.6548 - val_loss: 0.6676 - val_accuracy: 0.5714\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.5890 - accuracy: 0.7619 - val_loss: 0.6402 - val_accuracy: 0.5714\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5774 - accuracy: 0.7262 - val_loss: 0.6192 - val_accuracy: 0.7143\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.6218 - accuracy: 0.7024 - val_loss: 0.6095 - val_accuracy: 0.6667\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5296 - accuracy: 0.7619 - val_loss: 0.6052 - val_accuracy: 0.5714\n",
      "Epoch 27/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.6739 - accuracy: 0.6310 - val_loss: 0.5961 - val_accuracy: 0.6667\n",
      "Epoch 28/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5552 - accuracy: 0.7381 - val_loss: 0.5904 - val_accuracy: 0.7143\n",
      "Epoch 29/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5529 - accuracy: 0.7619 - val_loss: 0.5832 - val_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5518 - accuracy: 0.7381 - val_loss: 0.5783 - val_accuracy: 0.5714\n",
      "Epoch 31/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5352 - accuracy: 0.7738 - val_loss: 0.5807 - val_accuracy: 0.5714\n",
      "Epoch 32/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4557 - accuracy: 0.7976 - val_loss: 0.5735 - val_accuracy: 0.5714\n",
      "Epoch 33/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4794 - accuracy: 0.7976 - val_loss: 0.5572 - val_accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5252 - accuracy: 0.7262 - val_loss: 0.5543 - val_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5265 - accuracy: 0.7262 - val_loss: 0.5651 - val_accuracy: 0.5714\n",
      "Epoch 36/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4060 - accuracy: 0.8452 - val_loss: 0.5487 - val_accuracy: 0.6667\n",
      "Epoch 37/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4917 - accuracy: 0.7381 - val_loss: 0.5426 - val_accuracy: 0.6667\n",
      "Epoch 38/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4859 - accuracy: 0.7619 - val_loss: 0.5408 - val_accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4732 - accuracy: 0.7738 - val_loss: 0.5288 - val_accuracy: 0.7143\n",
      "Epoch 40/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4864 - accuracy: 0.7619 - val_loss: 0.5220 - val_accuracy: 0.7143\n",
      "Epoch 41/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5116 - accuracy: 0.7143 - val_loss: 0.5147 - val_accuracy: 0.7143\n",
      "Epoch 42/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4741 - accuracy: 0.7262 - val_loss: 0.5458 - val_accuracy: 0.5714\n",
      "Epoch 43/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4193 - accuracy: 0.7738 - val_loss: 0.5174 - val_accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5274 - accuracy: 0.6667 - val_loss: 0.4978 - val_accuracy: 0.8095\n",
      "Epoch 45/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4501 - accuracy: 0.7262 - val_loss: 0.4944 - val_accuracy: 0.8095\n",
      "Epoch 46/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4058 - accuracy: 0.7976 - val_loss: 0.4916 - val_accuracy: 0.8095\n",
      "Epoch 47/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4559 - accuracy: 0.7500 - val_loss: 0.5030 - val_accuracy: 0.7143\n",
      "Epoch 48/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4468 - accuracy: 0.7143 - val_loss: 0.4999 - val_accuracy: 0.7143\n",
      "Epoch 49/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4467 - accuracy: 0.7738 - val_loss: 0.4898 - val_accuracy: 0.7619\n",
      "Epoch 50/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4611 - accuracy: 0.7976 - val_loss: 0.5164 - val_accuracy: 0.6667\n",
      "Epoch 51/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3756 - accuracy: 0.8095 - val_loss: 0.4860 - val_accuracy: 0.7143\n",
      "Epoch 52/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4034 - accuracy: 0.8571 - val_loss: 0.4858 - val_accuracy: 0.7143\n",
      "Epoch 53/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3275 - accuracy: 0.8690 - val_loss: 0.4632 - val_accuracy: 0.8095\n",
      "Epoch 54/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3960 - accuracy: 0.8214 - val_loss: 0.4545 - val_accuracy: 0.8095\n",
      "Epoch 55/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4201 - accuracy: 0.7976 - val_loss: 0.4636 - val_accuracy: 0.8095\n",
      "Epoch 56/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3816 - accuracy: 0.8214 - val_loss: 0.4524 - val_accuracy: 0.8095\n",
      "Epoch 57/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4046 - accuracy: 0.8095 - val_loss: 0.4511 - val_accuracy: 0.8095\n",
      "Epoch 58/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3934 - accuracy: 0.7976 - val_loss: 0.4567 - val_accuracy: 0.8095\n",
      "Epoch 59/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3882 - accuracy: 0.7738 - val_loss: 0.4476 - val_accuracy: 0.8095\n",
      "Epoch 60/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3897 - accuracy: 0.8452 - val_loss: 0.4393 - val_accuracy: 0.8095\n",
      "Epoch 61/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3411 - accuracy: 0.8214 - val_loss: 0.4261 - val_accuracy: 0.8571\n",
      "Epoch 62/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4088 - accuracy: 0.7619 - val_loss: 0.4205 - val_accuracy: 0.9048\n",
      "Epoch 63/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3550 - accuracy: 0.8333 - val_loss: 0.4161 - val_accuracy: 0.8571\n",
      "Epoch 64/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3123 - accuracy: 0.8810 - val_loss: 0.4100 - val_accuracy: 0.8095\n",
      "Epoch 65/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3237 - accuracy: 0.8214 - val_loss: 0.4190 - val_accuracy: 0.8095\n",
      "Epoch 66/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3699 - accuracy: 0.8452 - val_loss: 0.3975 - val_accuracy: 0.9048\n",
      "Epoch 67/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3201 - accuracy: 0.8571 - val_loss: 0.4172 - val_accuracy: 0.8095\n",
      "Epoch 68/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2757 - accuracy: 0.8810 - val_loss: 0.3957 - val_accuracy: 0.8571\n",
      "Epoch 69/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3134 - accuracy: 0.8452 - val_loss: 0.3890 - val_accuracy: 0.9048\n",
      "Epoch 70/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4122 - accuracy: 0.7857 - val_loss: 0.3895 - val_accuracy: 0.9048\n",
      "Epoch 71/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3182 - accuracy: 0.8810 - val_loss: 0.3881 - val_accuracy: 0.9524\n",
      "Epoch 72/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3052 - accuracy: 0.8810 - val_loss: 0.4006 - val_accuracy: 0.8095\n",
      "Epoch 73/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3077 - accuracy: 0.8690 - val_loss: 0.3815 - val_accuracy: 0.9048\n",
      "Epoch 74/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2854 - accuracy: 0.8571 - val_loss: 0.3683 - val_accuracy: 0.9048\n",
      "Epoch 75/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3206 - accuracy: 0.8214 - val_loss: 0.3812 - val_accuracy: 0.8571\n",
      "Epoch 76/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3269 - accuracy: 0.8571 - val_loss: 0.3650 - val_accuracy: 0.9524\n",
      "Epoch 77/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3168 - accuracy: 0.8452 - val_loss: 0.3721 - val_accuracy: 0.8571\n",
      "Epoch 78/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2796 - accuracy: 0.9405 - val_loss: 0.3573 - val_accuracy: 0.9048\n",
      "Epoch 79/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2569 - accuracy: 0.9048 - val_loss: 0.3560 - val_accuracy: 0.9048\n",
      "Epoch 80/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3005 - accuracy: 0.8571 - val_loss: 0.3552 - val_accuracy: 0.9048\n",
      "Epoch 81/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2959 - accuracy: 0.9048 - val_loss: 0.3607 - val_accuracy: 0.9048\n",
      "Epoch 82/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2939 - accuracy: 0.8810 - val_loss: 0.3633 - val_accuracy: 0.8571\n",
      "Epoch 83/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3458 - accuracy: 0.8333 - val_loss: 0.3411 - val_accuracy: 0.9048\n",
      "Epoch 84/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2510 - accuracy: 0.9048 - val_loss: 0.3347 - val_accuracy: 0.9048\n",
      "Epoch 85/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2407 - accuracy: 0.8929 - val_loss: 0.3658 - val_accuracy: 0.8571\n",
      "Epoch 86/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2628 - accuracy: 0.8690 - val_loss: 0.3356 - val_accuracy: 0.9048\n",
      "Epoch 87/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2664 - accuracy: 0.8810 - val_loss: 0.3358 - val_accuracy: 0.9048\n",
      "Epoch 88/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2541 - accuracy: 0.8810 - val_loss: 0.3272 - val_accuracy: 0.9048\n",
      "Epoch 89/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.1954 - accuracy: 0.9524 - val_loss: 0.3194 - val_accuracy: 0.9524\n",
      "Epoch 90/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3357 - accuracy: 0.8333 - val_loss: 0.3301 - val_accuracy: 0.9048\n",
      "Epoch 91/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2876 - accuracy: 0.8929 - val_loss: 0.3363 - val_accuracy: 0.9048\n",
      "Epoch 92/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2041 - accuracy: 0.9048 - val_loss: 0.3142 - val_accuracy: 0.9048\n",
      "Epoch 93/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2769 - accuracy: 0.8690 - val_loss: 0.3169 - val_accuracy: 0.9048\n",
      "Epoch 94/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3105 - accuracy: 0.8690 - val_loss: 0.3163 - val_accuracy: 0.9048\n",
      "Epoch 95/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2730 - accuracy: 0.8929 - val_loss: 0.3269 - val_accuracy: 0.9048\n",
      "Epoch 96/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2670 - accuracy: 0.8929 - val_loss: 0.3155 - val_accuracy: 0.9048\n",
      "Epoch 97/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2480 - accuracy: 0.8690 - val_loss: 0.3175 - val_accuracy: 0.9048\n",
      "Epoch 98/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2166 - accuracy: 0.9048 - val_loss: 0.3059 - val_accuracy: 0.9048\n",
      "Epoch 99/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2532 - accuracy: 0.8929 - val_loss: 0.3075 - val_accuracy: 0.9048\n",
      "Epoch 100/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2855 - accuracy: 0.8690 - val_loss: 0.3085 - val_accuracy: 0.9048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6d341507b8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=4)\n",
    "model_keras = Sequential()\n",
    "\n",
    "# Define the first layer\n",
    "model_keras.add(keras.layers.Dense(36, activation='relu', input_shape = (4,)))\n",
    "model_keras.add(keras.layers.Dropout(0.2))\n",
    "# Add activation function to classifier\n",
    "model_keras.add(keras.layers.Dense(18, activation='relu'))\n",
    "model_keras.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model_keras.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "# Finish the model compilation\n",
    "model_keras.compile(optimizer = keras.optimizers.Adam(lr=0.001), \n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Complete the model fit operation\n",
    "model_keras.fit(X_train, Y_train_cat, epochs=100, batch_size=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.97410355e+01, 2.58947849e-01, 1.04498822e-05],\n",
       "       [4.23765487e-05, 2.16794705e+00, 9.78320160e+01],\n",
       "       [9.19663608e-01, 9.47299500e+01, 4.35038042e+00],\n",
       "       [9.96918945e+01, 3.08101773e-01, 1.36246053e-05],\n",
       "       [6.58379650e+00, 9.13582001e+01, 2.05800152e+00],\n",
       "       [6.49128497e-01, 9.04704666e+01, 8.88040161e+00],\n",
       "       [9.96066132e+01, 3.93368900e-01, 2.52439841e-05],\n",
       "       [2.72298465e-04, 3.20517969e+00, 9.67945404e+01],\n",
       "       [9.98876953e+01, 1.12304814e-01, 1.23335872e-06],\n",
       "       [2.77127552e+00, 9.28820038e+01, 4.34672976e+00],\n",
       "       [6.06254907e-05, 2.50134230e+00, 9.74986038e+01],\n",
       "       [4.92937386e-01, 8.97329178e+01, 9.77414513e+00],\n",
       "       [9.98976135e+01, 1.02390639e-01, 9.48249863e-07],\n",
       "       [9.98300018e+01, 1.70002639e-01, 3.19305445e-06],\n",
       "       [1.55264467e-01, 8.34965134e+01, 1.63482208e+01],\n",
       "       [9.97842560e+01, 2.15725929e-01, 6.50186121e-06],\n",
       "       [2.77450472e-01, 9.18374634e+01, 7.88508415e+00],\n",
       "       [8.48529510e-07, 5.05010068e-01, 9.94949951e+01],\n",
       "       [4.94300439e-05, 1.67752695e+00, 9.83224258e+01],\n",
       "       [8.64887759e-02, 6.12192917e+01, 3.86942139e+01],\n",
       "       [9.99677505e+01, 3.22501399e-02, 6.09398896e-08],\n",
       "       [9.00394693e-02, 6.81999817e+01, 3.17099743e+01],\n",
       "       [9.96508408e+01, 3.49136263e-01, 1.89707607e-05],\n",
       "       [2.72298465e-04, 3.20517969e+00, 9.67945404e+01],\n",
       "       [4.44520701e-05, 1.87741923e+00, 9.81225281e+01],\n",
       "       [2.94758856e-01, 9.12698975e+01, 8.43534946e+00],\n",
       "       [1.46877050e-04, 2.68301010e+00, 9.73168411e+01],\n",
       "       [1.97985306e-01, 8.99433899e+01, 9.85862446e+00],\n",
       "       [9.52890423e-06, 8.58182371e-01, 9.91417999e+01],\n",
       "       [9.97756195e+01, 2.24368319e-01, 6.96162397e-06],\n",
       "       [9.96119156e+01, 3.88059556e-01, 2.61550504e-05],\n",
       "       [9.97305145e+01, 2.69477010e-01, 9.38215726e-06],\n",
       "       [5.91469109e-02, 6.48649979e+01, 3.50758553e+01],\n",
       "       [9.97375259e+01, 2.62468427e-01, 9.89387445e-06],\n",
       "       [9.99033127e+01, 9.66892019e-02, 7.93137474e-07],\n",
       "       [9.97378845e+01, 2.62110919e-01, 9.76863066e-06],\n",
       "       [4.36232694e-05, 2.73698616e+00, 9.72629700e+01],\n",
       "       [9.98625183e+01, 1.37487784e-01, 1.89720902e-06],\n",
       "       [9.98111343e+01, 1.88859269e-01, 3.71423744e-06],\n",
       "       [4.65597492e-03, 1.46018877e+01, 8.53934631e+01],\n",
       "       [2.00573658e-03, 9.08339977e+00, 9.09145966e+01],\n",
       "       [9.96396103e+01, 3.60369653e-01, 1.93605920e-05],\n",
       "       [9.98235703e+01, 1.76428929e-01, 3.92769789e-06],\n",
       "       [2.21565555e-04, 6.08695507e+00, 9.39128189e+01],\n",
       "       [1.67169255e-05, 1.36676276e+00, 9.86332169e+01],\n",
       "       [1.74392189e-04, 2.41096568e+00, 9.75888672e+01],\n",
       "       [9.96816711e+01, 3.18318069e-01, 1.22218435e-05],\n",
       "       [3.42161942e+00, 9.47821350e+01, 1.79624891e+00],\n",
       "       [2.48393917e-05, 1.47940481e+00, 9.85205688e+01],\n",
       "       [9.98539200e+01, 1.46084979e-01, 2.41771022e-06],\n",
       "       [9.97030869e+01, 2.96902567e-01, 1.24043727e-05],\n",
       "       [7.60122028e-04, 6.07557011e+00, 9.39236755e+01],\n",
       "       [5.08049525e-05, 1.83434153e+00, 9.81656113e+01],\n",
       "       [9.99678040e+01, 3.22007351e-02, 6.11406392e-08],\n",
       "       [6.63665295e-01, 9.32606812e+01, 6.07566071e+00],\n",
       "       [9.99036789e+01, 9.63182971e-02, 7.50774120e-07],\n",
       "       [1.61155150e-03, 5.42060709e+00, 9.45777740e+01],\n",
       "       [2.47877724e-05, 2.64562297e+00, 9.73543549e+01],\n",
       "       [9.96425323e+01, 3.57444108e-01, 2.20078018e-05],\n",
       "       [2.03762946e-04, 3.93156624e+00, 9.60682297e+01],\n",
       "       [1.45135462e-01, 8.56832352e+01, 1.41716347e+01],\n",
       "       [8.22248310e-02, 8.27831650e+01, 1.71346226e+01],\n",
       "       [1.28719475e-04, 3.28953719e+00, 9.67103348e+01],\n",
       "       [9.98227539e+01, 1.77249193e-01, 3.56578698e-06],\n",
       "       [2.25634896e-04, 4.10135603e+00, 9.58984222e+01],\n",
       "       [9.98546906e+01, 1.45305514e-01, 2.24642577e-06],\n",
       "       [4.40818489e-01, 8.95050354e+01, 1.00541458e+01],\n",
       "       [4.72776359e-03, 1.97175121e+01, 8.02777634e+01],\n",
       "       [9.99036789e+01, 9.63209569e-02, 8.40756513e-07],\n",
       "       [3.44950527e-01, 8.58564682e+01, 1.37985811e+01],\n",
       "       [9.95246353e+01, 4.75323468e-01, 4.21850018e-05],\n",
       "       [3.23106760e-05, 1.46899712e+00, 9.85309753e+01],\n",
       "       [1.31256700e-01, 8.18223419e+01, 1.80464058e+01],\n",
       "       [7.61551200e-06, 1.35168540e+00, 9.86483002e+01],\n",
       "       [9.98722458e+01, 1.27745241e-01, 1.66454424e-06],\n",
       "       [2.42258247e-05, 1.30313802e+00, 9.86968307e+01],\n",
       "       [4.20732358e-05, 2.93976665e+00, 9.70601959e+01],\n",
       "       [1.11036596e-03, 7.06294346e+00, 9.29359512e+01],\n",
       "       [5.88657223e-02, 7.20127258e+01, 2.79284039e+01],\n",
       "       [9.99100952e+01, 8.99093002e-02, 6.69662541e-07],\n",
       "       [9.99006424e+01, 9.93610024e-02, 9.24546669e-07],\n",
       "       [3.75631469e-04, 3.29890800e+00, 9.67007141e+01],\n",
       "       [2.47574411e-03, 1.15064869e+01, 8.84910431e+01],\n",
       "       [9.98099518e+01, 1.90054923e-01, 3.81914970e-06],\n",
       "       [3.36683601e-01, 7.87386856e+01, 2.09246445e+01],\n",
       "       [4.17834148e-04, 1.36837940e+01, 8.63157959e+01],\n",
       "       [1.20766264e-04, 2.42608690e+00, 9.75737839e+01],\n",
       "       [2.03603282e-04, 3.39971447e+00, 9.66000824e+01],\n",
       "       [1.20522978e-03, 7.85518217e+00, 9.21436157e+01],\n",
       "       [9.98126831e+01, 1.87323317e-01, 4.22203311e-06],\n",
       "       [2.66472343e-04, 3.88258410e+00, 9.61171494e+01],\n",
       "       [9.98929901e+01, 1.07011989e-01, 1.05069807e-06],\n",
       "       [1.28270034e-03, 8.52495098e+00, 9.14737625e+01],\n",
       "       [5.58599234e-01, 7.91836548e+01, 2.02577496e+01],\n",
       "       [1.15007948e-04, 2.43464899e+00, 9.75652313e+01],\n",
       "       [3.57890531e-05, 1.51690650e+00, 9.84830627e+01],\n",
       "       [9.98642654e+01, 1.35733992e-01, 2.12122677e-06],\n",
       "       [5.07718069e-04, 6.24429846e+00, 9.37551880e+01],\n",
       "       [3.20797563e-01, 9.26007462e+01, 7.07845259e+00],\n",
       "       [3.48926522e-02, 4.39005432e+01, 5.60645599e+01],\n",
       "       [7.76706785e-02, 6.98354568e+01, 3.00868721e+01],\n",
       "       [1.46815320e-02, 3.00115051e+01, 6.99738159e+01],\n",
       "       [1.15259647e+00, 9.27323914e+01, 6.11501408e+00],\n",
       "       [9.97838058e+01, 2.16199800e-01, 5.65960909e-06],\n",
       "       [7.80553997e-01, 9.45120087e+01, 4.70743418e+00]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.array(model_keras.predict(X_train))\n",
    "\n",
    "predictions*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(\n",
    "    model_keras, to_file='model.png', show_shapes=False, show_layer_names=True,\n",
    "    rankdir='TB', expand_nested=False, dpi=96\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
