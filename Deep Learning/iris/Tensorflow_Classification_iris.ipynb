{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tensorflow import constant\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow import feature_column \n",
    "from tensorflow import estimator\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(df.drop('species',axis=1))\n",
    "Y = np.array(df['species'])\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Le = LabelEncoder()\n",
    "Le.fit(['setosa', 'virginica', 'versicolor'])\n",
    "Y_new = Le.transform(Y)\n",
    "Y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_new, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "84/84 [==============================] - 2s 20ms/sample - loss: 1.5002 - accuracy: 0.3571 - val_loss: 0.8912 - val_accuracy: 0.3810\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 1.2437 - accuracy: 0.4643 - val_loss: 0.8329 - val_accuracy: 0.5714\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 1.1557 - accuracy: 0.5238 - val_loss: 0.7903 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.9978 - accuracy: 0.5357 - val_loss: 0.7899 - val_accuracy: 0.5714\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 1.0622 - accuracy: 0.4524 - val_loss: 0.7892 - val_accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.8870 - accuracy: 0.5952 - val_loss: 0.7650 - val_accuracy: 0.5714\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.8878 - accuracy: 0.5119 - val_loss: 0.7302 - val_accuracy: 0.5714\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.7972 - accuracy: 0.6310 - val_loss: 0.7109 - val_accuracy: 0.5714\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.8938 - accuracy: 0.5714 - val_loss: 0.7190 - val_accuracy: 0.5714\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.7298 - accuracy: 0.6667 - val_loss: 0.7194 - val_accuracy: 0.5714\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.7791 - accuracy: 0.6667 - val_loss: 0.6946 - val_accuracy: 0.5714\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.7666 - accuracy: 0.6310 - val_loss: 0.6873 - val_accuracy: 0.5714\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.7509 - accuracy: 0.6429 - val_loss: 0.6852 - val_accuracy: 0.5714\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6702 - accuracy: 0.7381 - val_loss: 0.6653 - val_accuracy: 0.5714\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6616 - accuracy: 0.6548 - val_loss: 0.6639 - val_accuracy: 0.5714\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6869 - accuracy: 0.6905 - val_loss: 0.6451 - val_accuracy: 0.5714\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.7116 - accuracy: 0.6905 - val_loss: 0.6379 - val_accuracy: 0.5714\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.5773 - accuracy: 0.7381 - val_loss: 0.6304 - val_accuracy: 0.5714\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6242 - accuracy: 0.7024 - val_loss: 0.6006 - val_accuracy: 0.6190\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6586 - accuracy: 0.6667 - val_loss: 0.5946 - val_accuracy: 0.6190\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.5727 - accuracy: 0.7024 - val_loss: 0.6062 - val_accuracy: 0.5714\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.5665 - accuracy: 0.7262 - val_loss: 0.5954 - val_accuracy: 0.5714\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.5498 - accuracy: 0.7262 - val_loss: 0.5758 - val_accuracy: 0.5714\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.5619 - accuracy: 0.7262 - val_loss: 0.5664 - val_accuracy: 0.6190\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4887 - accuracy: 0.7381 - val_loss: 0.5604 - val_accuracy: 0.5714\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 0s 862us/sample - loss: 0.5272 - accuracy: 0.7381 - val_loss: 0.5399 - val_accuracy: 0.6667\n",
      "Epoch 27/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.5180 - accuracy: 0.8095 - val_loss: 0.5243 - val_accuracy: 0.7143\n",
      "Epoch 28/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.5047 - accuracy: 0.7500 - val_loss: 0.5150 - val_accuracy: 0.6667\n",
      "Epoch 29/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4275 - accuracy: 0.7857 - val_loss: 0.4947 - val_accuracy: 0.7619\n",
      "Epoch 30/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.5241 - accuracy: 0.7024 - val_loss: 0.5002 - val_accuracy: 0.7143\n",
      "Epoch 31/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4545 - accuracy: 0.7738 - val_loss: 0.4899 - val_accuracy: 0.7619\n",
      "Epoch 32/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4246 - accuracy: 0.8690 - val_loss: 0.4898 - val_accuracy: 0.7619\n",
      "Epoch 33/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4329 - accuracy: 0.8214 - val_loss: 0.4991 - val_accuracy: 0.7143\n",
      "Epoch 34/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4281 - accuracy: 0.7738 - val_loss: 0.4781 - val_accuracy: 0.7619\n",
      "Epoch 35/100\n",
      "84/84 [==============================] - 0s 955us/sample - loss: 0.4610 - accuracy: 0.7381 - val_loss: 0.4515 - val_accuracy: 0.8571\n",
      "Epoch 36/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4380 - accuracy: 0.7619 - val_loss: 0.4529 - val_accuracy: 0.8095\n",
      "Epoch 37/100\n",
      "84/84 [==============================] - 0s 905us/sample - loss: 0.3934 - accuracy: 0.8333 - val_loss: 0.4465 - val_accuracy: 0.8095\n",
      "Epoch 38/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4263 - accuracy: 0.8214 - val_loss: 0.4437 - val_accuracy: 0.8095\n",
      "Epoch 39/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4343 - accuracy: 0.7976 - val_loss: 0.4323 - val_accuracy: 0.8095\n",
      "Epoch 40/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3692 - accuracy: 0.8214 - val_loss: 0.4279 - val_accuracy: 0.8095\n",
      "Epoch 41/100\n",
      "84/84 [==============================] - 0s 928us/sample - loss: 0.3354 - accuracy: 0.8810 - val_loss: 0.4289 - val_accuracy: 0.8095\n",
      "Epoch 42/100\n",
      "84/84 [==============================] - 0s 869us/sample - loss: 0.4131 - accuracy: 0.7619 - val_loss: 0.4429 - val_accuracy: 0.8095\n",
      "Epoch 43/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4127 - accuracy: 0.7857 - val_loss: 0.4205 - val_accuracy: 0.8095\n",
      "Epoch 44/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3315 - accuracy: 0.8571 - val_loss: 0.3939 - val_accuracy: 0.9048\n",
      "Epoch 45/100\n",
      "84/84 [==============================] - 0s 920us/sample - loss: 0.4127 - accuracy: 0.7857 - val_loss: 0.3911 - val_accuracy: 0.9048\n",
      "Epoch 46/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2916 - accuracy: 0.8452 - val_loss: 0.3907 - val_accuracy: 0.9048\n",
      "Epoch 47/100\n",
      "84/84 [==============================] - 0s 941us/sample - loss: 0.3289 - accuracy: 0.8690 - val_loss: 0.3890 - val_accuracy: 0.8571\n",
      "Epoch 48/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2914 - accuracy: 0.8690 - val_loss: 0.3889 - val_accuracy: 0.8571\n",
      "Epoch 49/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3456 - accuracy: 0.8095 - val_loss: 0.3861 - val_accuracy: 0.8571\n",
      "Epoch 50/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3095 - accuracy: 0.8690 - val_loss: 0.3721 - val_accuracy: 0.9048\n",
      "Epoch 51/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3334 - accuracy: 0.8571 - val_loss: 0.3915 - val_accuracy: 0.8571\n",
      "Epoch 52/100\n",
      "84/84 [==============================] - 0s 972us/sample - loss: 0.3596 - accuracy: 0.8214 - val_loss: 0.3609 - val_accuracy: 0.9048\n",
      "Epoch 53/100\n",
      "84/84 [==============================] - 0s 952us/sample - loss: 0.3591 - accuracy: 0.8333 - val_loss: 0.3765 - val_accuracy: 0.8571\n",
      "Epoch 54/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2973 - accuracy: 0.8690 - val_loss: 0.3658 - val_accuracy: 0.9048\n",
      "Epoch 55/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2837 - accuracy: 0.8929 - val_loss: 0.3625 - val_accuracy: 0.9048\n",
      "Epoch 56/100\n",
      "84/84 [==============================] - 0s 927us/sample - loss: 0.3008 - accuracy: 0.8810 - val_loss: 0.3494 - val_accuracy: 0.9048\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2923 - accuracy: 0.8571 - val_loss: 0.3491 - val_accuracy: 0.9048\n",
      "Epoch 58/100\n",
      "84/84 [==============================] - 0s 858us/sample - loss: 0.2673 - accuracy: 0.8690 - val_loss: 0.3574 - val_accuracy: 0.9048\n",
      "Epoch 59/100\n",
      "84/84 [==============================] - 0s 968us/sample - loss: 0.2518 - accuracy: 0.8929 - val_loss: 0.3343 - val_accuracy: 0.8571\n",
      "Epoch 60/100\n",
      "84/84 [==============================] - 0s 939us/sample - loss: 0.2758 - accuracy: 0.9048 - val_loss: 0.3307 - val_accuracy: 0.9048\n",
      "Epoch 61/100\n",
      "84/84 [==============================] - 0s 847us/sample - loss: 0.3400 - accuracy: 0.8571 - val_loss: 0.3311 - val_accuracy: 0.9048\n",
      "Epoch 62/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3237 - accuracy: 0.8571 - val_loss: 0.3205 - val_accuracy: 0.9048\n",
      "Epoch 63/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2994 - accuracy: 0.9167 - val_loss: 0.3459 - val_accuracy: 0.9048\n",
      "Epoch 64/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2806 - accuracy: 0.9048 - val_loss: 0.3118 - val_accuracy: 0.9048\n",
      "Epoch 65/100\n",
      "84/84 [==============================] - 0s 935us/sample - loss: 0.2553 - accuracy: 0.9048 - val_loss: 0.3091 - val_accuracy: 0.9048\n",
      "Epoch 66/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2390 - accuracy: 0.9048 - val_loss: 0.3291 - val_accuracy: 0.9048\n",
      "Epoch 67/100\n",
      "84/84 [==============================] - 0s 900us/sample - loss: 0.3158 - accuracy: 0.8571 - val_loss: 0.3296 - val_accuracy: 0.9048\n",
      "Epoch 68/100\n",
      "84/84 [==============================] - 0s 894us/sample - loss: 0.2357 - accuracy: 0.9286 - val_loss: 0.3046 - val_accuracy: 0.9048\n",
      "Epoch 69/100\n",
      "84/84 [==============================] - 0s 890us/sample - loss: 0.2307 - accuracy: 0.9167 - val_loss: 0.3171 - val_accuracy: 0.9048\n",
      "Epoch 70/100\n",
      "84/84 [==============================] - 0s 923us/sample - loss: 0.2277 - accuracy: 0.9167 - val_loss: 0.2935 - val_accuracy: 0.9048\n",
      "Epoch 71/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2250 - accuracy: 0.9167 - val_loss: 0.2936 - val_accuracy: 0.9048\n",
      "Epoch 72/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2104 - accuracy: 0.8810 - val_loss: 0.2948 - val_accuracy: 0.9048\n",
      "Epoch 73/100\n",
      "84/84 [==============================] - 0s 922us/sample - loss: 0.2737 - accuracy: 0.8333 - val_loss: 0.2915 - val_accuracy: 0.9048\n",
      "Epoch 74/100\n",
      "84/84 [==============================] - 0s 879us/sample - loss: 0.2045 - accuracy: 0.9286 - val_loss: 0.2907 - val_accuracy: 0.9048\n",
      "Epoch 75/100\n",
      "84/84 [==============================] - 0s 947us/sample - loss: 0.2251 - accuracy: 0.8810 - val_loss: 0.2893 - val_accuracy: 0.9048\n",
      "Epoch 76/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2575 - accuracy: 0.8929 - val_loss: 0.3323 - val_accuracy: 0.9048\n",
      "Epoch 77/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2368 - accuracy: 0.9167 - val_loss: 0.2822 - val_accuracy: 0.9048\n",
      "Epoch 78/100\n",
      "84/84 [==============================] - 0s 937us/sample - loss: 0.2020 - accuracy: 0.9048 - val_loss: 0.2849 - val_accuracy: 0.9048\n",
      "Epoch 79/100\n",
      "84/84 [==============================] - 0s 901us/sample - loss: 0.2314 - accuracy: 0.8690 - val_loss: 0.3064 - val_accuracy: 0.9048\n",
      "Epoch 80/100\n",
      "84/84 [==============================] - 0s 965us/sample - loss: 0.2007 - accuracy: 0.9524 - val_loss: 0.2842 - val_accuracy: 0.9048\n",
      "Epoch 81/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2260 - accuracy: 0.8929 - val_loss: 0.2915 - val_accuracy: 0.9048\n",
      "Epoch 82/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.1968 - accuracy: 0.9048 - val_loss: 0.2830 - val_accuracy: 0.9048\n",
      "Epoch 83/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2140 - accuracy: 0.9167 - val_loss: 0.2851 - val_accuracy: 0.9048\n",
      "Epoch 84/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.1809 - accuracy: 0.9405 - val_loss: 0.3095 - val_accuracy: 0.9048\n",
      "Epoch 85/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.1978 - accuracy: 0.9048 - val_loss: 0.2997 - val_accuracy: 0.9048\n",
      "Epoch 86/100\n",
      "84/84 [==============================] - 0s 965us/sample - loss: 0.2030 - accuracy: 0.9405 - val_loss: 0.2767 - val_accuracy: 0.9048\n",
      "Epoch 87/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2155 - accuracy: 0.9286 - val_loss: 0.2927 - val_accuracy: 0.9048\n",
      "Epoch 88/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.1721 - accuracy: 0.9405 - val_loss: 0.2846 - val_accuracy: 0.9048\n",
      "Epoch 89/100\n",
      "84/84 [==============================] - 0s 923us/sample - loss: 0.2331 - accuracy: 0.8929 - val_loss: 0.2772 - val_accuracy: 0.9048\n",
      "Epoch 90/100\n",
      "84/84 [==============================] - 0s 929us/sample - loss: 0.2931 - accuracy: 0.9048 - val_loss: 0.2793 - val_accuracy: 0.9048\n",
      "Epoch 91/100\n",
      "84/84 [==============================] - 0s 906us/sample - loss: 0.2198 - accuracy: 0.9286 - val_loss: 0.2768 - val_accuracy: 0.9048\n",
      "Epoch 92/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2050 - accuracy: 0.9405 - val_loss: 0.2739 - val_accuracy: 0.9048\n",
      "Epoch 93/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.1974 - accuracy: 0.9286 - val_loss: 0.2725 - val_accuracy: 0.9048\n",
      "Epoch 94/100\n",
      "84/84 [==============================] - 0s 912us/sample - loss: 0.1841 - accuracy: 0.9167 - val_loss: 0.2705 - val_accuracy: 0.9048\n",
      "Epoch 95/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.1359 - accuracy: 0.9881 - val_loss: 0.3141 - val_accuracy: 0.9048\n",
      "Epoch 96/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.1848 - accuracy: 0.9405 - val_loss: 0.2843 - val_accuracy: 0.9048\n",
      "Epoch 97/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2024 - accuracy: 0.9286 - val_loss: 0.2679 - val_accuracy: 0.8571\n",
      "Epoch 98/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2352 - accuracy: 0.8929 - val_loss: 0.2706 - val_accuracy: 0.9048\n",
      "Epoch 99/100\n",
      "84/84 [==============================] - 0s 911us/sample - loss: 0.1979 - accuracy: 0.9286 - val_loss: 0.2666 - val_accuracy: 0.9048\n",
      "Epoch 100/100\n",
      "84/84 [==============================] - 0s 947us/sample - loss: 0.2188 - accuracy: 0.8929 - val_loss: 0.2759 - val_accuracy: 0.9048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1fd8727048>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_keras = Sequential()\n",
    "\n",
    "# Define the first layer\n",
    "model_keras.add(keras.layers.Dense(36, activation='relu', input_shape = (4,)))\n",
    "model_keras.add(keras.layers.Dropout(0.2))\n",
    "# Add activation function to classifier\n",
    "model_keras.add(keras.layers.Dense(18, activation='relu'))\n",
    "model_keras.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model_keras.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "# Finish the model compilation\n",
    "model_keras.compile(optimizer=keras.optimizers.Adam(lr=0.001), \n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# Complete the model fit operation\n",
    "model_keras.fit(X_train, Y_train, epochs=100, batch_size=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 1, 2, 1, 1, 2, 0, 2, 0, 0, 2, 2, 1, 1, 1, 0, 2, 1, 0,\n",
       "       1, 1, 1, 1, 1, 2, 0, 0, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 0, 0, 0, 1,\n",
       "       1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.array(model_keras.predict_classes(X_test))\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'setosa', 'setosa', 'virginica', 'versicolor',\n",
       "       'virginica', 'versicolor', 'versicolor', 'virginica', 'setosa',\n",
       "       'virginica', 'setosa', 'setosa', 'virginica', 'virginica',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'setosa', 'virginica',\n",
       "       'versicolor', 'setosa', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'virginica', 'setosa', 'setosa',\n",
       "       'virginica', 'versicolor', 'virginica', 'versicolor', 'virginica',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'virginica', 'setosa', 'setosa', 'setosa', 'versicolor',\n",
       "       'versicolor'], dtype='<U10')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_predictions = Le.inverse_transform(predictions)\n",
    "new_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species      setosa  versicolor  virginica\n",
      "predictions                               \n",
      "setosa           13           0          0\n",
      "versicolor        0          20          0\n",
      "virginica         0           0         12\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.DataFrame({'predictions': new_predictions, 'species': Le.inverse_transform(Y_test)})\n",
    "\n",
    "# Create crosstab: ct\n",
    "ct3 = pd.crosstab(df3['predictions'], df3['species'])\n",
    "print(ct3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 0, 1, 1, 0, 2, 0, 1, 2, 1, 0, 0, 1, 0, 1, 2, 2, 2, 0, 1,\n",
       "       0, 2, 2, 1, 2, 1, 2, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2,\n",
       "       2, 2, 0, 1, 2, 0, 0, 2, 2, 0, 1, 0, 2, 2, 0, 2, 1, 1, 2, 0, 2, 0,\n",
       "       1, 2, 0, 1, 0, 2, 1, 2, 0, 2, 2, 2, 1, 0, 0, 2, 2, 0, 1, 2, 2, 2,\n",
       "       2, 0, 2, 0, 2, 1, 2, 2, 0, 2, 1, 1, 1, 2, 1, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.array(model_keras.predict_classes(X_train))\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'virginica', 'versicolor', 'setosa', 'versicolor',\n",
       "       'versicolor', 'setosa', 'virginica', 'setosa', 'versicolor',\n",
       "       'virginica', 'versicolor', 'setosa', 'setosa', 'versicolor',\n",
       "       'setosa', 'versicolor', 'virginica', 'virginica', 'virginica',\n",
       "       'setosa', 'versicolor', 'setosa', 'virginica', 'virginica',\n",
       "       'versicolor', 'virginica', 'versicolor', 'virginica', 'setosa',\n",
       "       'setosa', 'setosa', 'versicolor', 'setosa', 'setosa', 'setosa',\n",
       "       'virginica', 'setosa', 'setosa', 'virginica', 'virginica',\n",
       "       'setosa', 'setosa', 'virginica', 'virginica', 'virginica',\n",
       "       'setosa', 'versicolor', 'virginica', 'setosa', 'setosa',\n",
       "       'virginica', 'virginica', 'setosa', 'versicolor', 'setosa',\n",
       "       'virginica', 'virginica', 'setosa', 'virginica', 'versicolor',\n",
       "       'versicolor', 'virginica', 'setosa', 'virginica', 'setosa',\n",
       "       'versicolor', 'virginica', 'setosa', 'versicolor', 'setosa',\n",
       "       'virginica', 'versicolor', 'virginica', 'setosa', 'virginica',\n",
       "       'virginica', 'virginica', 'versicolor', 'setosa', 'setosa',\n",
       "       'virginica', 'virginica', 'setosa', 'versicolor', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'setosa', 'virginica',\n",
       "       'setosa', 'virginica', 'versicolor', 'virginica', 'virginica',\n",
       "       'setosa', 'virginica', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'virginica', 'versicolor', 'setosa', 'versicolor'], dtype='<U10')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_predictions = Le.inverse_transform(predictions)\n",
    "new_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species      setosa  versicolor  virginica\n",
      "predictions                               \n",
      "setosa           37           0          0\n",
      "versicolor        0          26          0\n",
      "virginica         0           4         38\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.DataFrame({'predictions': new_predictions, 'species': Le.inverse_transform(Y_train)})\n",
    "\n",
    "# Create crosstab: ct\n",
    "ct3 = pd.crosstab(df3['predictions'], df3['species'])\n",
    "print(ct3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Le = LabelEncoder()\n",
    "Le.fit(['setosa', 'virginica', 'versicolor'])\n",
    "Y_new = Le.transform(Y)\n",
    "Y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_new, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_cat = to_categorical(Y_train)\n",
    "Y_test_cat = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "84/84 [==============================] - 1s 15ms/sample - loss: 2.9426 - accuracy: 0.2500 - val_loss: 1.3644 - val_accuracy: 0.0476\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 2.1690 - accuracy: 0.3452 - val_loss: 1.1062 - val_accuracy: 0.1905\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 2.1813 - accuracy: 0.3095 - val_loss: 1.0790 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 1.5778 - accuracy: 0.3333 - val_loss: 1.0984 - val_accuracy: 0.5714\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 1.5993 - accuracy: 0.3571 - val_loss: 1.1404 - val_accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 1.2188 - accuracy: 0.5357 - val_loss: 1.0459 - val_accuracy: 0.5714\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 1.2440 - accuracy: 0.3810 - val_loss: 0.9798 - val_accuracy: 0.5714\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 1.1138 - accuracy: 0.4524 - val_loss: 0.9852 - val_accuracy: 0.5714\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 1.0562 - accuracy: 0.5119 - val_loss: 0.9501 - val_accuracy: 0.5714\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 0s 936us/sample - loss: 1.1840 - accuracy: 0.4643 - val_loss: 0.9213 - val_accuracy: 0.5714\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.9978 - accuracy: 0.5119 - val_loss: 0.9028 - val_accuracy: 0.5714\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 0s 974us/sample - loss: 1.1713 - accuracy: 0.4286 - val_loss: 0.8963 - val_accuracy: 0.5714\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.8622 - accuracy: 0.6071 - val_loss: 0.8576 - val_accuracy: 0.5714\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.8934 - accuracy: 0.5357 - val_loss: 0.8274 - val_accuracy: 0.5714\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.8956 - accuracy: 0.5476 - val_loss: 0.8017 - val_accuracy: 0.5714\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.8231 - accuracy: 0.5714 - val_loss: 0.7961 - val_accuracy: 0.5714\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 0s 947us/sample - loss: 0.8648 - accuracy: 0.5595 - val_loss: 0.7652 - val_accuracy: 0.5714\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.8204 - accuracy: 0.5833 - val_loss: 0.7439 - val_accuracy: 0.5714\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.7544 - accuracy: 0.6310 - val_loss: 0.7228 - val_accuracy: 0.5714\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.7709 - accuracy: 0.5833 - val_loss: 0.7011 - val_accuracy: 0.5714\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6954 - accuracy: 0.6548 - val_loss: 0.6855 - val_accuracy: 0.5714\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6508 - accuracy: 0.7143 - val_loss: 0.6763 - val_accuracy: 0.5714\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6882 - accuracy: 0.5476 - val_loss: 0.6717 - val_accuracy: 0.5714\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.7017 - accuracy: 0.6786 - val_loss: 0.6707 - val_accuracy: 0.5714\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6330 - accuracy: 0.6786 - val_loss: 0.6658 - val_accuracy: 0.5714\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6996 - accuracy: 0.6071 - val_loss: 0.6607 - val_accuracy: 0.5714\n",
      "Epoch 27/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6367 - accuracy: 0.7262 - val_loss: 0.6494 - val_accuracy: 0.5714\n",
      "Epoch 28/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6400 - accuracy: 0.6786 - val_loss: 0.6400 - val_accuracy: 0.5714\n",
      "Epoch 29/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6938 - accuracy: 0.6429 - val_loss: 0.6362 - val_accuracy: 0.5714\n",
      "Epoch 30/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6391 - accuracy: 0.7024 - val_loss: 0.6292 - val_accuracy: 0.5714\n",
      "Epoch 31/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6283 - accuracy: 0.6786 - val_loss: 0.6204 - val_accuracy: 0.5714\n",
      "Epoch 32/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6329 - accuracy: 0.6786 - val_loss: 0.6123 - val_accuracy: 0.5714\n",
      "Epoch 33/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5737 - accuracy: 0.6786 - val_loss: 0.6081 - val_accuracy: 0.5714\n",
      "Epoch 34/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6041 - accuracy: 0.6786 - val_loss: 0.6045 - val_accuracy: 0.5714\n",
      "Epoch 35/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6089 - accuracy: 0.7143 - val_loss: 0.6036 - val_accuracy: 0.5714\n",
      "Epoch 36/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5330 - accuracy: 0.7500 - val_loss: 0.5988 - val_accuracy: 0.5714\n",
      "Epoch 37/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5680 - accuracy: 0.7500 - val_loss: 0.5930 - val_accuracy: 0.5714\n",
      "Epoch 38/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.5802 - accuracy: 0.7500 - val_loss: 0.5968 - val_accuracy: 0.5714\n",
      "Epoch 39/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4882 - accuracy: 0.7619 - val_loss: 0.6000 - val_accuracy: 0.5714\n",
      "Epoch 40/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4857 - accuracy: 0.7500 - val_loss: 0.5852 - val_accuracy: 0.5714\n",
      "Epoch 41/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.5101 - accuracy: 0.7262 - val_loss: 0.5927 - val_accuracy: 0.5714\n",
      "Epoch 42/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4947 - accuracy: 0.7500 - val_loss: 0.5740 - val_accuracy: 0.5714\n",
      "Epoch 43/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6135 - accuracy: 0.6905 - val_loss: 0.5735 - val_accuracy: 0.5714\n",
      "Epoch 44/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.5241 - accuracy: 0.7143 - val_loss: 0.5759 - val_accuracy: 0.5714\n",
      "Epoch 45/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4571 - accuracy: 0.7857 - val_loss: 0.5693 - val_accuracy: 0.5714\n",
      "Epoch 46/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4742 - accuracy: 0.7976 - val_loss: 0.5494 - val_accuracy: 0.5714\n",
      "Epoch 47/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5219 - accuracy: 0.7500 - val_loss: 0.5346 - val_accuracy: 0.6190\n",
      "Epoch 48/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4844 - accuracy: 0.7857 - val_loss: 0.5282 - val_accuracy: 0.5714\n",
      "Epoch 49/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4379 - accuracy: 0.7500 - val_loss: 0.5187 - val_accuracy: 0.7143\n",
      "Epoch 50/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4424 - accuracy: 0.7738 - val_loss: 0.5105 - val_accuracy: 0.7143\n",
      "Epoch 51/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4969 - accuracy: 0.7976 - val_loss: 0.5113 - val_accuracy: 0.7143\n",
      "Epoch 52/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.5013 - accuracy: 0.7857 - val_loss: 0.5146 - val_accuracy: 0.7143\n",
      "Epoch 53/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.5683 - accuracy: 0.7024 - val_loss: 0.5231 - val_accuracy: 0.5714\n",
      "Epoch 54/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4823 - accuracy: 0.7619 - val_loss: 0.5178 - val_accuracy: 0.5714\n",
      "Epoch 55/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4066 - accuracy: 0.8452 - val_loss: 0.4997 - val_accuracy: 0.7143\n",
      "Epoch 56/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4778 - accuracy: 0.7976 - val_loss: 0.4924 - val_accuracy: 0.7143\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4709 - accuracy: 0.7381 - val_loss: 0.4878 - val_accuracy: 0.7143\n",
      "Epoch 58/100\n",
      "84/84 [==============================] - 0s 926us/sample - loss: 0.4107 - accuracy: 0.7738 - val_loss: 0.5059 - val_accuracy: 0.6667\n",
      "Epoch 59/100\n",
      "84/84 [==============================] - 0s 938us/sample - loss: 0.4508 - accuracy: 0.7976 - val_loss: 0.4890 - val_accuracy: 0.7143\n",
      "Epoch 60/100\n",
      "84/84 [==============================] - 0s 905us/sample - loss: 0.4204 - accuracy: 0.7738 - val_loss: 0.4654 - val_accuracy: 0.7143\n",
      "Epoch 61/100\n",
      "84/84 [==============================] - 0s 817us/sample - loss: 0.4027 - accuracy: 0.8571 - val_loss: 0.4581 - val_accuracy: 0.7619\n",
      "Epoch 62/100\n",
      "84/84 [==============================] - 0s 934us/sample - loss: 0.4697 - accuracy: 0.7857 - val_loss: 0.4446 - val_accuracy: 0.8095\n",
      "Epoch 63/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3724 - accuracy: 0.8690 - val_loss: 0.4495 - val_accuracy: 0.8095\n",
      "Epoch 64/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3786 - accuracy: 0.7976 - val_loss: 0.4873 - val_accuracy: 0.7143\n",
      "Epoch 65/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3889 - accuracy: 0.8571 - val_loss: 0.4468 - val_accuracy: 0.7619\n",
      "Epoch 66/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3704 - accuracy: 0.8095 - val_loss: 0.4545 - val_accuracy: 0.7143\n",
      "Epoch 67/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3557 - accuracy: 0.8452 - val_loss: 0.4068 - val_accuracy: 0.9048\n",
      "Epoch 68/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3535 - accuracy: 0.8452 - val_loss: 0.4291 - val_accuracy: 0.8095\n",
      "Epoch 69/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3658 - accuracy: 0.8571 - val_loss: 0.4282 - val_accuracy: 0.8095\n",
      "Epoch 70/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4360 - accuracy: 0.7500 - val_loss: 0.4089 - val_accuracy: 0.8571\n",
      "Epoch 71/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3687 - accuracy: 0.7976 - val_loss: 0.4092 - val_accuracy: 0.8571\n",
      "Epoch 72/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3853 - accuracy: 0.8333 - val_loss: 0.3918 - val_accuracy: 0.9048\n",
      "Epoch 73/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3839 - accuracy: 0.8095 - val_loss: 0.3781 - val_accuracy: 0.9048\n",
      "Epoch 74/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3538 - accuracy: 0.8214 - val_loss: 0.3862 - val_accuracy: 0.9048\n",
      "Epoch 75/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3496 - accuracy: 0.8452 - val_loss: 0.3892 - val_accuracy: 0.9048\n",
      "Epoch 76/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3632 - accuracy: 0.8095 - val_loss: 0.3672 - val_accuracy: 0.9048\n",
      "Epoch 77/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3684 - accuracy: 0.8571 - val_loss: 0.3668 - val_accuracy: 0.9048\n",
      "Epoch 78/100\n",
      "84/84 [==============================] - 0s 993us/sample - loss: 0.3333 - accuracy: 0.8452 - val_loss: 0.3765 - val_accuracy: 0.9048\n",
      "Epoch 79/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3046 - accuracy: 0.8452 - val_loss: 0.3689 - val_accuracy: 0.9048\n",
      "Epoch 80/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3238 - accuracy: 0.9048 - val_loss: 0.3665 - val_accuracy: 0.9048\n",
      "Epoch 81/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3324 - accuracy: 0.8571 - val_loss: 0.3419 - val_accuracy: 0.9048\n",
      "Epoch 82/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3707 - accuracy: 0.8214 - val_loss: 0.3796 - val_accuracy: 0.8095\n",
      "Epoch 83/100\n",
      "84/84 [==============================] - 0s 909us/sample - loss: 0.3517 - accuracy: 0.8214 - val_loss: 0.3793 - val_accuracy: 0.8095\n",
      "Epoch 84/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3184 - accuracy: 0.8333 - val_loss: 0.3456 - val_accuracy: 0.9048\n",
      "Epoch 85/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3556 - accuracy: 0.8214 - val_loss: 0.3352 - val_accuracy: 0.9048\n",
      "Epoch 86/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2786 - accuracy: 0.9405 - val_loss: 0.3293 - val_accuracy: 0.9048\n",
      "Epoch 87/100\n",
      "84/84 [==============================] - 0s 868us/sample - loss: 0.2900 - accuracy: 0.8810 - val_loss: 0.3507 - val_accuracy: 0.9048\n",
      "Epoch 88/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3471 - accuracy: 0.8690 - val_loss: 0.3771 - val_accuracy: 0.8095\n",
      "Epoch 89/100\n",
      "84/84 [==============================] - 0s 929us/sample - loss: 0.3655 - accuracy: 0.7976 - val_loss: 0.3273 - val_accuracy: 0.9048\n",
      "Epoch 90/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2850 - accuracy: 0.8810 - val_loss: 0.3217 - val_accuracy: 0.9048\n",
      "Epoch 91/100\n",
      "84/84 [==============================] - 0s 3ms/sample - loss: 0.2849 - accuracy: 0.8929 - val_loss: 0.3365 - val_accuracy: 0.9048\n",
      "Epoch 92/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3125 - accuracy: 0.8571 - val_loss: 0.3442 - val_accuracy: 0.9048\n",
      "Epoch 93/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2742 - accuracy: 0.8929 - val_loss: 0.3100 - val_accuracy: 0.9048\n",
      "Epoch 94/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2703 - accuracy: 0.8810 - val_loss: 0.3114 - val_accuracy: 0.9048\n",
      "Epoch 95/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3115 - accuracy: 0.8095 - val_loss: 0.3231 - val_accuracy: 0.9048\n",
      "Epoch 96/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3142 - accuracy: 0.8571 - val_loss: 0.3004 - val_accuracy: 0.9048\n",
      "Epoch 97/100\n",
      "84/84 [==============================] - 0s 975us/sample - loss: 0.2877 - accuracy: 0.8690 - val_loss: 0.3132 - val_accuracy: 0.9048\n",
      "Epoch 98/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2437 - accuracy: 0.8810 - val_loss: 0.2951 - val_accuracy: 0.9048\n",
      "Epoch 99/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3270 - accuracy: 0.8452 - val_loss: 0.3237 - val_accuracy: 0.9048\n",
      "Epoch 100/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2298 - accuracy: 0.9167 - val_loss: 0.3168 - val_accuracy: 0.9048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1fb9ce85c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=4)\n",
    "model_keras = Sequential()\n",
    "\n",
    "# Define the first layer\n",
    "model_keras.add(keras.layers.Dense(36, activation='relu', input_shape = (4,)))\n",
    "model_keras.add(keras.layers.Dropout(0.2))\n",
    "# Add activation function to classifier\n",
    "model_keras.add(keras.layers.Dense(18, activation='relu'))\n",
    "model_keras.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model_keras.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "# Finish the model compilation\n",
    "model_keras.compile(optimizer = keras.optimizers.Adam(lr=0.001), \n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Complete the model fit operation\n",
    "model_keras.fit(X_train, Y_train_cat, epochs=100, batch_size=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.89120865e+01, 1.08638275e+00, 1.53488677e-03],\n",
       "       [1.73419795e-03, 7.73583221e+00, 9.22624435e+01],\n",
       "       [1.61639941e+00, 8.52983627e+01, 1.30852299e+01],\n",
       "       [9.89716263e+01, 1.02697814e+00, 1.39902090e-03],\n",
       "       [8.22355747e+00, 8.53146667e+01, 6.46178198e+00],\n",
       "       [1.36710382e+00, 8.11012650e+01, 1.75316296e+01],\n",
       "       [9.86584930e+01, 1.33926618e+00, 2.24957382e-03],\n",
       "       [8.69734399e-03, 1.05596218e+01, 8.94316711e+01],\n",
       "       [9.94234772e+01, 5.76176107e-01, 3.59118916e-04],\n",
       "       [4.03570986e+00, 8.34446640e+01, 1.25196190e+01],\n",
       "       [1.85628759e-03, 8.00681210e+00, 9.19913330e+01],\n",
       "       [1.16501462e+00, 8.13431931e+01, 1.74917927e+01],\n",
       "       [9.94279404e+01, 5.71722329e-01, 3.45551729e-04],\n",
       "       [9.93170776e+01, 6.82382107e-01, 5.44200942e-04],\n",
       "       [4.83662158e-01, 7.11270370e+01, 2.83893013e+01],\n",
       "       [9.89451828e+01, 1.05345786e+00, 1.35634339e-03],\n",
       "       [8.26502800e-01, 8.33436508e+01, 1.58298492e+01],\n",
       "       [1.27846739e-04, 4.23566341e+00, 9.57642136e+01],\n",
       "       [4.50150389e-03, 9.01663876e+00, 9.09788666e+01],\n",
       "       [2.53894061e-01, 4.24959373e+01, 5.72501678e+01],\n",
       "       [9.98146057e+01, 1.85373917e-01, 2.59417247e-05],\n",
       "       [3.46479714e-01, 6.16175461e+01, 3.80359726e+01],\n",
       "       [9.86948013e+01, 1.30289555e+00, 2.30136630e-03],\n",
       "       [8.69734399e-03, 1.05596218e+01, 8.94316711e+01],\n",
       "       [2.51958054e-03, 8.01312733e+00, 9.19843521e+01],\n",
       "       [9.19454992e-01, 7.87474899e+01, 2.03330593e+01],\n",
       "       [7.79973762e-03, 1.05336342e+01, 8.94585571e+01],\n",
       "       [5.72634041e-01, 8.22234879e+01, 1.72038784e+01],\n",
       "       [1.80485391e-03, 7.16467047e+00, 9.28335266e+01],\n",
       "       [9.91053162e+01, 8.93669844e-01, 1.01229304e-03],\n",
       "       [9.87810745e+01, 1.21687567e+00, 2.04794807e-03],\n",
       "       [9.90777969e+01, 9.21094298e-01, 1.10789121e-03],\n",
       "       [2.91729838e-01, 6.88813171e+01, 3.08269596e+01],\n",
       "       [9.89146500e+01, 1.08382165e+00, 1.52718183e-03],\n",
       "       [9.94335098e+01, 5.66151321e-01, 3.31772608e-04],\n",
       "       [9.89444656e+01, 1.05419946e+00, 1.33207755e-03],\n",
       "       [1.38838100e-03, 8.45882034e+00, 9.15397949e+01],\n",
       "       [9.94179993e+01, 5.81626892e-01, 3.78782162e-04],\n",
       "       [9.93224564e+01, 6.77008629e-01, 5.34742314e-04],\n",
       "       [6.12190180e-02, 2.73202629e+01, 7.26185226e+01],\n",
       "       [4.18557972e-02, 2.50837841e+01, 7.48743668e+01],\n",
       "       [9.87525482e+01, 1.24537635e+00, 2.08749413e-03],\n",
       "       [9.93523941e+01, 6.47122622e-01, 4.83279146e-04],\n",
       "       [5.50712226e-03, 1.43226013e+01, 8.56718979e+01],\n",
       "       [1.59681926e-03, 7.25591946e+00, 9.27424850e+01],\n",
       "       [7.46844290e-03, 1.01435575e+01, 8.98489685e+01],\n",
       "       [9.86204147e+01, 1.37722158e+00, 2.36697751e-03],\n",
       "       [4.58909512e+00, 8.90692596e+01, 6.34164953e+00],\n",
       "       [1.84518506e-03, 7.34580755e+00, 9.26523438e+01],\n",
       "       [9.93603287e+01, 6.39208198e-01, 4.59713105e-04],\n",
       "       [9.90199356e+01, 9.78788197e-01, 1.27178722e-03],\n",
       "       [9.89262760e-03, 1.25855875e+01, 8.74045258e+01],\n",
       "       [2.75297021e-03, 8.15776062e+00, 9.18394928e+01],\n",
       "       [9.97528229e+01, 2.47130260e-01, 4.88979713e-05],\n",
       "       [1.49291337e+00, 8.64585953e+01, 1.20484934e+01],\n",
       "       [9.95710373e+01, 4.28784817e-01, 1.82006857e-04],\n",
       "       [3.33187915e-02, 1.42563343e+01, 8.57103500e+01],\n",
       "       [1.24726247e-03, 7.93401384e+00, 9.20647430e+01],\n",
       "       [9.86643066e+01, 1.33320594e+00, 2.49656616e-03],\n",
       "       [4.90352139e-03, 9.69002724e+00, 9.03050690e+01],\n",
       "       [5.09882271e-01, 7.42405624e+01, 2.52495537e+01],\n",
       "       [3.26896906e-01, 7.76836395e+01, 2.19894600e+01],\n",
       "       [4.61631641e-03, 9.80696201e+00, 9.01884232e+01],\n",
       "       [9.92565155e+01, 7.42831051e-01, 6.51155773e-04],\n",
       "       [8.58257338e-03, 1.46670084e+01, 8.53244095e+01],\n",
       "       [9.94290237e+01, 5.70604324e-01, 3.64284584e-04],\n",
       "       [1.11928797e+00, 7.88595581e+01, 2.00211487e+01],\n",
       "       [4.53249887e-02, 2.87367077e+01, 7.12179718e+01],\n",
       "       [9.96177216e+01, 3.82140011e-01, 1.43841695e-04],\n",
       "       [8.16642582e-01, 8.08338165e+01, 1.83495388e+01],\n",
       "       [9.83932648e+01, 1.60297847e+00, 3.76774161e-03],\n",
       "       [2.41129962e-03, 7.69981432e+00, 9.22977753e+01],\n",
       "       [3.77536058e-01, 6.77126312e+01, 3.19098377e+01],\n",
       "       [4.55397036e-04, 5.69416904e+00, 9.43053741e+01],\n",
       "       [9.94284897e+01, 5.71149766e-01, 3.58899095e-04],\n",
       "       [2.36978685e-03, 7.62336779e+00, 9.23742599e+01],\n",
       "       [1.29609136e-03, 8.06658649e+00, 9.19321213e+01],\n",
       "       [1.78440791e-02, 1.37823954e+01, 8.61997604e+01],\n",
       "       [2.64782727e-01, 7.37325592e+01, 2.60026493e+01],\n",
       "       [9.95737686e+01, 4.26059604e-01, 1.82920194e-04],\n",
       "       [9.94282608e+01, 5.71411073e-01, 3.36173165e-04],\n",
       "       [1.35040758e-02, 1.16134100e+01, 8.83730850e+01],\n",
       "       [3.76154520e-02, 2.66375217e+01, 7.33248672e+01],\n",
       "       [9.89959335e+01, 1.00299740e+00, 1.07552286e-03],\n",
       "       [9.14370716e-01, 6.62550964e+01, 3.28305359e+01],\n",
       "       [9.53061320e-03, 2.59442806e+01, 7.40461960e+01],\n",
       "       [6.28818898e-03, 9.97649384e+00, 9.00172195e+01],\n",
       "       [5.19987056e-03, 9.86596966e+00, 9.01288300e+01],\n",
       "       [1.64970737e-02, 1.45841808e+01, 8.53993225e+01],\n",
       "       [9.92786713e+01, 7.20696092e-01, 6.23888569e-04],\n",
       "       [1.42801628e-02, 1.86180878e+01, 8.13676300e+01],\n",
       "       [9.94215546e+01, 5.78113973e-01, 3.29952571e-04],\n",
       "       [3.35901715e-02, 2.49159641e+01, 7.50504456e+01],\n",
       "       [1.27791154e+00, 7.22569046e+01, 2.64651871e+01],\n",
       "       [5.79587743e-03, 1.06834269e+01, 8.93107834e+01],\n",
       "       [2.45419098e-03, 7.88647699e+00, 9.21110764e+01],\n",
       "       [9.93745193e+01, 6.25032306e-01, 4.36636532e-04],\n",
       "       [1.00537334e-02, 1.31156120e+01, 8.68743286e+01],\n",
       "       [8.71727347e-01, 8.63852158e+01, 1.27430620e+01],\n",
       "       [2.21969470e-01, 6.15394135e+01, 3.82386208e+01],\n",
       "       [2.70044476e-01, 5.89817886e+01, 4.07481651e+01],\n",
       "       [1.00960828e-01, 3.31219406e+01, 6.67770996e+01],\n",
       "       [2.01487112e+00, 8.40254211e+01, 1.39597073e+01],\n",
       "       [9.90152512e+01, 9.83559370e-01, 1.17495342e-03],\n",
       "       [1.57403874e+00, 8.32336807e+01, 1.51922684e+01]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.array(model_keras.predict(X_train))\n",
    "\n",
    "predictions*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"dot\" with args ['-Tps', '/tmp/tmpeu851xlr'] returned code: -11\n",
      "\n",
      "stdout, stderr:\n",
      " b''\n",
      "b'Warning: Could not load \"/home/sinisha/miniconda3/lib/graphviz/libgvplugin_pango.so.6\" - file not found\\n'\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "-11",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9ffade9f8985>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m plot_model(\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel_keras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mrankdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TB'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_nested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[1;32m    281\u001b[0m                      \u001b[0mrankdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrankdir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                      \u001b[0mexpand_nested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_nested\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                      dpi=dpi)\n\u001b[0m\u001b[1;32m    284\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'IPython.core.magics.namespace'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0;31m# We don't raise an exception here in order to avoid crashing notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mcheck_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Attempt to create an image of a blank graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1943\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1945\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1947\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstdout_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: -11"
     ]
    }
   ],
   "source": [
    "plot_model(\n",
    "    model_keras, to_file='model.png', show_shapes=False, show_layer_names=True,\n",
    "    rankdir='TB', expand_nested=False, dpi=96\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
