{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tensorflow import constant\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow import feature_column \n",
    "from tensorflow import estimator\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(df.drop('species',axis=1))\n",
    "Y = np.array(df['species'])\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Le = LabelEncoder()\n",
    "Le.fit(['setosa', 'virginica', 'versicolor'])\n",
    "Y_new = Le.transform(Y)\n",
    "Y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_new, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "84/84 [==============================] - 3s 38ms/sample - loss: 1.6517 - accuracy: 0.4643 - val_loss: 0.8652 - val_accuracy: 0.6190\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 1.3076 - accuracy: 0.4762 - val_loss: 0.8609 - val_accuracy: 0.5714\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 1.0523 - accuracy: 0.5476 - val_loss: 0.8512 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 1.0851 - accuracy: 0.5238 - val_loss: 0.8072 - val_accuracy: 0.5714\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.8828 - accuracy: 0.5833 - val_loss: 0.7476 - val_accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.7464 - accuracy: 0.6667 - val_loss: 0.7181 - val_accuracy: 0.5714\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.7574 - accuracy: 0.7024 - val_loss: 0.7080 - val_accuracy: 0.5714\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.7237 - accuracy: 0.6310 - val_loss: 0.6836 - val_accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.6388 - accuracy: 0.6548 - val_loss: 0.6625 - val_accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6016 - accuracy: 0.7738 - val_loss: 0.6586 - val_accuracy: 0.5714\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.7019 - accuracy: 0.6905 - val_loss: 0.6344 - val_accuracy: 0.5714\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5804 - accuracy: 0.7381 - val_loss: 0.6259 - val_accuracy: 0.5714\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.6457 - accuracy: 0.7143 - val_loss: 0.6196 - val_accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.6607 - accuracy: 0.6548 - val_loss: 0.6092 - val_accuracy: 0.5714\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5801 - accuracy: 0.7143 - val_loss: 0.6020 - val_accuracy: 0.5714\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.6117 - accuracy: 0.7381 - val_loss: 0.5933 - val_accuracy: 0.5714\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5962 - accuracy: 0.7262 - val_loss: 0.5773 - val_accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5936 - accuracy: 0.7381 - val_loss: 0.5715 - val_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5462 - accuracy: 0.7976 - val_loss: 0.5755 - val_accuracy: 0.5714\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5365 - accuracy: 0.7738 - val_loss: 0.5772 - val_accuracy: 0.5714\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5224 - accuracy: 0.7262 - val_loss: 0.5627 - val_accuracy: 0.6667\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4898 - accuracy: 0.7738 - val_loss: 0.5595 - val_accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4860 - accuracy: 0.7857 - val_loss: 0.5575 - val_accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4483 - accuracy: 0.7857 - val_loss: 0.5748 - val_accuracy: 0.5714\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4869 - accuracy: 0.7619 - val_loss: 0.5677 - val_accuracy: 0.5714\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5127 - accuracy: 0.7024 - val_loss: 0.5544 - val_accuracy: 0.5714\n",
      "Epoch 27/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.5403 - accuracy: 0.7143 - val_loss: 0.5338 - val_accuracy: 0.6667\n",
      "Epoch 28/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.5478 - accuracy: 0.6548 - val_loss: 0.5284 - val_accuracy: 0.7143\n",
      "Epoch 29/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4400 - accuracy: 0.7738 - val_loss: 0.5273 - val_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4638 - accuracy: 0.7738 - val_loss: 0.5180 - val_accuracy: 0.7143\n",
      "Epoch 31/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4750 - accuracy: 0.8333 - val_loss: 0.5259 - val_accuracy: 0.6667\n",
      "Epoch 32/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4626 - accuracy: 0.8095 - val_loss: 0.5147 - val_accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4552 - accuracy: 0.7381 - val_loss: 0.5180 - val_accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4752 - accuracy: 0.7024 - val_loss: 0.5061 - val_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4983 - accuracy: 0.6786 - val_loss: 0.4937 - val_accuracy: 0.8095\n",
      "Epoch 36/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4175 - accuracy: 0.7976 - val_loss: 0.4914 - val_accuracy: 0.8095\n",
      "Epoch 37/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4180 - accuracy: 0.7619 - val_loss: 0.4915 - val_accuracy: 0.7619\n",
      "Epoch 38/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4294 - accuracy: 0.7619 - val_loss: 0.4873 - val_accuracy: 0.7619\n",
      "Epoch 39/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4022 - accuracy: 0.8214 - val_loss: 0.4739 - val_accuracy: 0.8095\n",
      "Epoch 40/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4634 - accuracy: 0.7262 - val_loss: 0.4696 - val_accuracy: 0.8095\n",
      "Epoch 41/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4329 - accuracy: 0.7262 - val_loss: 0.4880 - val_accuracy: 0.7619\n",
      "Epoch 42/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4258 - accuracy: 0.7738 - val_loss: 0.4844 - val_accuracy: 0.7619\n",
      "Epoch 43/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3788 - accuracy: 0.8690 - val_loss: 0.4792 - val_accuracy: 0.7619\n",
      "Epoch 44/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3922 - accuracy: 0.7857 - val_loss: 0.4641 - val_accuracy: 0.8095\n",
      "Epoch 45/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4126 - accuracy: 0.8333 - val_loss: 0.4742 - val_accuracy: 0.7619\n",
      "Epoch 46/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3518 - accuracy: 0.8214 - val_loss: 0.4675 - val_accuracy: 0.7619\n",
      "Epoch 47/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3977 - accuracy: 0.8333 - val_loss: 0.4493 - val_accuracy: 0.8095\n",
      "Epoch 48/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4185 - accuracy: 0.7619 - val_loss: 0.4639 - val_accuracy: 0.7619\n",
      "Epoch 49/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4840 - accuracy: 0.7143 - val_loss: 0.4558 - val_accuracy: 0.8095\n",
      "Epoch 50/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3654 - accuracy: 0.8810 - val_loss: 0.4492 - val_accuracy: 0.8095\n",
      "Epoch 51/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3375 - accuracy: 0.8810 - val_loss: 0.4379 - val_accuracy: 0.8095\n",
      "Epoch 52/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3570 - accuracy: 0.8690 - val_loss: 0.4389 - val_accuracy: 0.8095\n",
      "Epoch 53/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3601 - accuracy: 0.8333 - val_loss: 0.4303 - val_accuracy: 0.8095\n",
      "Epoch 54/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3408 - accuracy: 0.8690 - val_loss: 0.4083 - val_accuracy: 0.9048\n",
      "Epoch 55/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3729 - accuracy: 0.8095 - val_loss: 0.4280 - val_accuracy: 0.8095\n",
      "Epoch 56/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3131 - accuracy: 0.9048 - val_loss: 0.4329 - val_accuracy: 0.8095\n",
      "Epoch 57/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4198 - accuracy: 0.8333 - val_loss: 0.4113 - val_accuracy: 0.8571\n",
      "Epoch 58/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3035 - accuracy: 0.8929 - val_loss: 0.3764 - val_accuracy: 0.9048\n",
      "Epoch 59/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3402 - accuracy: 0.8571 - val_loss: 0.3663 - val_accuracy: 0.9048\n",
      "Epoch 60/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3679 - accuracy: 0.7976 - val_loss: 0.3987 - val_accuracy: 0.8571\n",
      "Epoch 61/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3587 - accuracy: 0.8333 - val_loss: 0.4101 - val_accuracy: 0.8571\n",
      "Epoch 62/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3153 - accuracy: 0.8452 - val_loss: 0.3786 - val_accuracy: 0.8571\n",
      "Epoch 63/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3648 - accuracy: 0.8333 - val_loss: 0.4140 - val_accuracy: 0.8095\n",
      "Epoch 64/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3309 - accuracy: 0.8690 - val_loss: 0.3769 - val_accuracy: 0.9048\n",
      "Epoch 65/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3533 - accuracy: 0.8452 - val_loss: 0.3746 - val_accuracy: 0.9048\n",
      "Epoch 66/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3264 - accuracy: 0.8333 - val_loss: 0.3654 - val_accuracy: 0.9048\n",
      "Epoch 67/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3180 - accuracy: 0.8690 - val_loss: 0.3662 - val_accuracy: 0.9048\n",
      "Epoch 68/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2672 - accuracy: 0.8810 - val_loss: 0.3697 - val_accuracy: 0.9048\n",
      "Epoch 69/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3398 - accuracy: 0.8214 - val_loss: 0.3647 - val_accuracy: 0.9048\n",
      "Epoch 70/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2904 - accuracy: 0.8690 - val_loss: 0.3996 - val_accuracy: 0.8095\n",
      "Epoch 71/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2980 - accuracy: 0.8333 - val_loss: 0.3432 - val_accuracy: 0.9048\n",
      "Epoch 72/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3186 - accuracy: 0.8571 - val_loss: 0.3213 - val_accuracy: 0.9048\n",
      "Epoch 73/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2938 - accuracy: 0.8690 - val_loss: 0.3861 - val_accuracy: 0.8571\n",
      "Epoch 74/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3328 - accuracy: 0.8810 - val_loss: 0.3677 - val_accuracy: 0.8571\n",
      "Epoch 75/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2413 - accuracy: 0.9167 - val_loss: 0.3429 - val_accuracy: 0.9048\n",
      "Epoch 76/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2970 - accuracy: 0.8690 - val_loss: 0.3227 - val_accuracy: 0.9048\n",
      "Epoch 77/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2844 - accuracy: 0.8333 - val_loss: 0.3186 - val_accuracy: 0.9048\n",
      "Epoch 78/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2391 - accuracy: 0.9048 - val_loss: 0.3325 - val_accuracy: 0.9048\n",
      "Epoch 79/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2279 - accuracy: 0.9286 - val_loss: 0.3725 - val_accuracy: 0.8571\n",
      "Epoch 80/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2783 - accuracy: 0.8571 - val_loss: 0.3380 - val_accuracy: 0.9048\n",
      "Epoch 81/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2902 - accuracy: 0.8929 - val_loss: 0.2975 - val_accuracy: 0.9048\n",
      "Epoch 82/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2505 - accuracy: 0.8452 - val_loss: 0.3019 - val_accuracy: 0.9048\n",
      "Epoch 83/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2436 - accuracy: 0.8810 - val_loss: 0.2942 - val_accuracy: 0.9048\n",
      "Epoch 84/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2586 - accuracy: 0.8929 - val_loss: 0.3316 - val_accuracy: 0.9048\n",
      "Epoch 85/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2219 - accuracy: 0.9286 - val_loss: 0.3697 - val_accuracy: 0.8571\n",
      "Epoch 86/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2970 - accuracy: 0.9048 - val_loss: 0.2839 - val_accuracy: 0.9048\n",
      "Epoch 87/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2128 - accuracy: 0.9167 - val_loss: 0.2812 - val_accuracy: 0.9048\n",
      "Epoch 88/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2141 - accuracy: 0.8929 - val_loss: 0.2792 - val_accuracy: 0.9048\n",
      "Epoch 89/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3501 - accuracy: 0.8333 - val_loss: 0.2817 - val_accuracy: 0.9048\n",
      "Epoch 90/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2752 - accuracy: 0.8690 - val_loss: 0.2823 - val_accuracy: 0.9048\n",
      "Epoch 91/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2458 - accuracy: 0.8810 - val_loss: 0.3457 - val_accuracy: 0.8571\n",
      "Epoch 92/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2308 - accuracy: 0.9167 - val_loss: 0.2902 - val_accuracy: 0.9048\n",
      "Epoch 93/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.1735 - accuracy: 0.9286 - val_loss: 0.2727 - val_accuracy: 0.9048\n",
      "Epoch 94/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2460 - accuracy: 0.8929 - val_loss: 0.2764 - val_accuracy: 0.9048\n",
      "Epoch 95/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2518 - accuracy: 0.8452 - val_loss: 0.2964 - val_accuracy: 0.9048\n",
      "Epoch 96/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2013 - accuracy: 0.8929 - val_loss: 0.2772 - val_accuracy: 0.9048\n",
      "Epoch 97/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.1684 - accuracy: 0.9405 - val_loss: 0.2935 - val_accuracy: 0.9048\n",
      "Epoch 98/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2222 - accuracy: 0.9048 - val_loss: 0.2952 - val_accuracy: 0.9048\n",
      "Epoch 99/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2558 - accuracy: 0.9048 - val_loss: 0.2737 - val_accuracy: 0.9048\n",
      "Epoch 100/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2334 - accuracy: 0.9048 - val_loss: 0.2770 - val_accuracy: 0.9048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6d3c3e5438>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_keras = Sequential()\n",
    "\n",
    "# Define the first layer\n",
    "model_keras.add(keras.layers.Dense(36, activation='relu', input_shape = (4,)))\n",
    "model_keras.add(keras.layers.Dropout(0.2))\n",
    "# Add activation function to classifier\n",
    "model_keras.add(keras.layers.Dense(18, activation='relu'))\n",
    "model_keras.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model_keras.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "# Finish the model compilation\n",
    "model_keras.compile(optimizer=keras.optimizers.Adam(lr=0.001), \n",
    "              loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# Complete the model fit operation\n",
    "model_keras.fit(X_train, Y_train, epochs=100, batch_size=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 1, 2, 2, 1, 2, 0, 2, 0, 0, 2, 2, 1, 1, 1, 0, 2, 1, 0,\n",
       "       1, 1, 1, 1, 1, 2, 0, 0, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 0, 0, 0, 1,\n",
       "       1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.array(model_keras.predict_classes(X_test))\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'setosa', 'setosa', 'virginica', 'versicolor',\n",
       "       'virginica', 'virginica', 'versicolor', 'virginica', 'setosa',\n",
       "       'virginica', 'setosa', 'setosa', 'virginica', 'virginica',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'setosa', 'virginica',\n",
       "       'versicolor', 'setosa', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'virginica', 'setosa', 'setosa',\n",
       "       'virginica', 'versicolor', 'virginica', 'versicolor', 'virginica',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'virginica', 'setosa', 'setosa', 'setosa', 'versicolor',\n",
       "       'versicolor'], dtype='<U10')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_predictions = Le.inverse_transform(predictions)\n",
    "new_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species      setosa  versicolor  virginica\n",
      "predictions                               \n",
      "setosa           13           0          0\n",
      "versicolor        0          19          0\n",
      "virginica         0           1         12\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.DataFrame({'predictions': new_predictions, 'species': Le.inverse_transform(Y_test)})\n",
    "\n",
    "# Create crosstab: ct\n",
    "ct3 = pd.crosstab(df3['predictions'], df3['species'])\n",
    "print(ct3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 0, 1, 1, 0, 2, 0, 1, 2, 1, 0, 0, 1, 0, 1, 2, 2, 2, 0, 1,\n",
       "       0, 2, 2, 1, 2, 1, 2, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 2,\n",
       "       2, 2, 0, 1, 2, 0, 0, 2, 2, 0, 1, 0, 2, 2, 0, 2, 1, 1, 2, 0, 2, 0,\n",
       "       1, 2, 0, 1, 0, 2, 1, 2, 0, 2, 2, 2, 1, 0, 0, 2, 2, 0, 1, 2, 2, 2,\n",
       "       2, 0, 2, 0, 2, 1, 2, 2, 0, 2, 1, 1, 1, 2, 1, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.array(model_keras.predict_classes(X_train))\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'virginica', 'versicolor', 'setosa', 'versicolor',\n",
       "       'versicolor', 'setosa', 'virginica', 'setosa', 'versicolor',\n",
       "       'virginica', 'versicolor', 'setosa', 'setosa', 'versicolor',\n",
       "       'setosa', 'versicolor', 'virginica', 'virginica', 'virginica',\n",
       "       'setosa', 'versicolor', 'setosa', 'virginica', 'virginica',\n",
       "       'versicolor', 'virginica', 'versicolor', 'virginica', 'setosa',\n",
       "       'setosa', 'setosa', 'versicolor', 'setosa', 'setosa', 'setosa',\n",
       "       'virginica', 'setosa', 'setosa', 'virginica', 'virginica',\n",
       "       'setosa', 'setosa', 'virginica', 'virginica', 'virginica',\n",
       "       'setosa', 'versicolor', 'virginica', 'setosa', 'setosa',\n",
       "       'virginica', 'virginica', 'setosa', 'versicolor', 'setosa',\n",
       "       'virginica', 'virginica', 'setosa', 'virginica', 'versicolor',\n",
       "       'versicolor', 'virginica', 'setosa', 'virginica', 'setosa',\n",
       "       'versicolor', 'virginica', 'setosa', 'versicolor', 'setosa',\n",
       "       'virginica', 'versicolor', 'virginica', 'setosa', 'virginica',\n",
       "       'virginica', 'virginica', 'versicolor', 'setosa', 'setosa',\n",
       "       'virginica', 'virginica', 'setosa', 'versicolor', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'setosa', 'virginica',\n",
       "       'setosa', 'virginica', 'versicolor', 'virginica', 'virginica',\n",
       "       'setosa', 'virginica', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'virginica', 'versicolor', 'setosa', 'versicolor'], dtype='<U10')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_predictions = Le.inverse_transform(predictions)\n",
    "new_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species      setosa  versicolor  virginica\n",
      "predictions                               \n",
      "setosa           37           0          0\n",
      "versicolor        0          26          0\n",
      "virginica         0           4         38\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.DataFrame({'predictions': new_predictions, 'species': Le.inverse_transform(Y_train)})\n",
    "\n",
    "# Create crosstab: ct\n",
    "ct3 = pd.crosstab(df3['predictions'], df3['species'])\n",
    "print(ct3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Le = LabelEncoder()\n",
    "Le.fit(['setosa', 'virginica', 'versicolor'])\n",
    "Y_new = Le.transform(Y)\n",
    "Y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_new, test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_cat = to_categorical(Y_train)\n",
    "Y_test_cat = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84 samples, validate on 21 samples\n",
      "Epoch 1/100\n",
      "84/84 [==============================] - 2s 18ms/sample - loss: 2.0503 - accuracy: 0.2976 - val_loss: 0.9608 - val_accuracy: 0.5714\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 1.3844 - accuracy: 0.4405 - val_loss: 0.9284 - val_accuracy: 0.5714\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 1.3837 - accuracy: 0.3929 - val_loss: 0.9007 - val_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 1.2924 - accuracy: 0.3690 - val_loss: 0.8737 - val_accuracy: 0.5714\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.9957 - accuracy: 0.4524 - val_loss: 0.8639 - val_accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 1.1834 - accuracy: 0.3810 - val_loss: 0.8582 - val_accuracy: 0.5714\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.9918 - accuracy: 0.5357 - val_loss: 0.8687 - val_accuracy: 0.5714\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.8698 - accuracy: 0.5952 - val_loss: 0.8773 - val_accuracy: 0.5714\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.9184 - accuracy: 0.5714 - val_loss: 0.8631 - val_accuracy: 0.5714\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.8880 - accuracy: 0.5714 - val_loss: 0.8399 - val_accuracy: 0.5714\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.9009 - accuracy: 0.5714 - val_loss: 0.8222 - val_accuracy: 0.5714\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.7563 - accuracy: 0.6429 - val_loss: 0.7971 - val_accuracy: 0.5714\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.7439 - accuracy: 0.6786 - val_loss: 0.7767 - val_accuracy: 0.5714\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.8353 - accuracy: 0.5833 - val_loss: 0.7632 - val_accuracy: 0.5714\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.7540 - accuracy: 0.6905 - val_loss: 0.7419 - val_accuracy: 0.5714\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.6539 - accuracy: 0.6667 - val_loss: 0.7223 - val_accuracy: 0.5714\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.7726 - accuracy: 0.6190 - val_loss: 0.7021 - val_accuracy: 0.5714\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.7977 - accuracy: 0.5833 - val_loss: 0.6832 - val_accuracy: 0.6190\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.7018 - accuracy: 0.6190 - val_loss: 0.6724 - val_accuracy: 0.5714\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.6175 - accuracy: 0.7143 - val_loss: 0.6702 - val_accuracy: 0.5714\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.6428 - accuracy: 0.6905 - val_loss: 0.6583 - val_accuracy: 0.5714\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.6853 - accuracy: 0.6548 - val_loss: 0.6676 - val_accuracy: 0.5714\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.5890 - accuracy: 0.7619 - val_loss: 0.6402 - val_accuracy: 0.5714\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5774 - accuracy: 0.7262 - val_loss: 0.6192 - val_accuracy: 0.7143\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.6218 - accuracy: 0.7024 - val_loss: 0.6095 - val_accuracy: 0.6667\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5296 - accuracy: 0.7619 - val_loss: 0.6052 - val_accuracy: 0.5714\n",
      "Epoch 27/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.6739 - accuracy: 0.6310 - val_loss: 0.5961 - val_accuracy: 0.6667\n",
      "Epoch 28/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5552 - accuracy: 0.7381 - val_loss: 0.5904 - val_accuracy: 0.7143\n",
      "Epoch 29/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5529 - accuracy: 0.7619 - val_loss: 0.5832 - val_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5518 - accuracy: 0.7381 - val_loss: 0.5783 - val_accuracy: 0.5714\n",
      "Epoch 31/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5352 - accuracy: 0.7738 - val_loss: 0.5807 - val_accuracy: 0.5714\n",
      "Epoch 32/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4557 - accuracy: 0.7976 - val_loss: 0.5735 - val_accuracy: 0.5714\n",
      "Epoch 33/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4794 - accuracy: 0.7976 - val_loss: 0.5572 - val_accuracy: 0.6667\n",
      "Epoch 34/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5252 - accuracy: 0.7262 - val_loss: 0.5543 - val_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5265 - accuracy: 0.7262 - val_loss: 0.5651 - val_accuracy: 0.5714\n",
      "Epoch 36/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4060 - accuracy: 0.8452 - val_loss: 0.5487 - val_accuracy: 0.6667\n",
      "Epoch 37/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4917 - accuracy: 0.7381 - val_loss: 0.5426 - val_accuracy: 0.6667\n",
      "Epoch 38/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4859 - accuracy: 0.7619 - val_loss: 0.5408 - val_accuracy: 0.6667\n",
      "Epoch 39/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4732 - accuracy: 0.7738 - val_loss: 0.5288 - val_accuracy: 0.7143\n",
      "Epoch 40/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4864 - accuracy: 0.7619 - val_loss: 0.5220 - val_accuracy: 0.7143\n",
      "Epoch 41/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5116 - accuracy: 0.7143 - val_loss: 0.5147 - val_accuracy: 0.7143\n",
      "Epoch 42/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4741 - accuracy: 0.7262 - val_loss: 0.5458 - val_accuracy: 0.5714\n",
      "Epoch 43/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4193 - accuracy: 0.7738 - val_loss: 0.5174 - val_accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.5274 - accuracy: 0.6667 - val_loss: 0.4978 - val_accuracy: 0.8095\n",
      "Epoch 45/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4501 - accuracy: 0.7262 - val_loss: 0.4944 - val_accuracy: 0.8095\n",
      "Epoch 46/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4058 - accuracy: 0.7976 - val_loss: 0.4916 - val_accuracy: 0.8095\n",
      "Epoch 47/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4559 - accuracy: 0.7500 - val_loss: 0.5030 - val_accuracy: 0.7143\n",
      "Epoch 48/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4468 - accuracy: 0.7143 - val_loss: 0.4999 - val_accuracy: 0.7143\n",
      "Epoch 49/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4467 - accuracy: 0.7738 - val_loss: 0.4898 - val_accuracy: 0.7619\n",
      "Epoch 50/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4611 - accuracy: 0.7976 - val_loss: 0.5164 - val_accuracy: 0.6667\n",
      "Epoch 51/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3756 - accuracy: 0.8095 - val_loss: 0.4860 - val_accuracy: 0.7143\n",
      "Epoch 52/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4034 - accuracy: 0.8571 - val_loss: 0.4858 - val_accuracy: 0.7143\n",
      "Epoch 53/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3275 - accuracy: 0.8690 - val_loss: 0.4632 - val_accuracy: 0.8095\n",
      "Epoch 54/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3960 - accuracy: 0.8214 - val_loss: 0.4545 - val_accuracy: 0.8095\n",
      "Epoch 55/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.4201 - accuracy: 0.7976 - val_loss: 0.4636 - val_accuracy: 0.8095\n",
      "Epoch 56/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3816 - accuracy: 0.8214 - val_loss: 0.4524 - val_accuracy: 0.8095\n",
      "Epoch 57/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4046 - accuracy: 0.8095 - val_loss: 0.4511 - val_accuracy: 0.8095\n",
      "Epoch 58/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3934 - accuracy: 0.7976 - val_loss: 0.4567 - val_accuracy: 0.8095\n",
      "Epoch 59/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3882 - accuracy: 0.7738 - val_loss: 0.4476 - val_accuracy: 0.8095\n",
      "Epoch 60/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3897 - accuracy: 0.8452 - val_loss: 0.4393 - val_accuracy: 0.8095\n",
      "Epoch 61/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3411 - accuracy: 0.8214 - val_loss: 0.4261 - val_accuracy: 0.8571\n",
      "Epoch 62/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4088 - accuracy: 0.7619 - val_loss: 0.4205 - val_accuracy: 0.9048\n",
      "Epoch 63/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3550 - accuracy: 0.8333 - val_loss: 0.4161 - val_accuracy: 0.8571\n",
      "Epoch 64/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3123 - accuracy: 0.8810 - val_loss: 0.4100 - val_accuracy: 0.8095\n",
      "Epoch 65/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3237 - accuracy: 0.8214 - val_loss: 0.4190 - val_accuracy: 0.8095\n",
      "Epoch 66/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3699 - accuracy: 0.8452 - val_loss: 0.3975 - val_accuracy: 0.9048\n",
      "Epoch 67/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3201 - accuracy: 0.8571 - val_loss: 0.4172 - val_accuracy: 0.8095\n",
      "Epoch 68/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2757 - accuracy: 0.8810 - val_loss: 0.3957 - val_accuracy: 0.8571\n",
      "Epoch 69/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3134 - accuracy: 0.8452 - val_loss: 0.3890 - val_accuracy: 0.9048\n",
      "Epoch 70/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.4122 - accuracy: 0.7857 - val_loss: 0.3895 - val_accuracy: 0.9048\n",
      "Epoch 71/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3182 - accuracy: 0.8810 - val_loss: 0.3881 - val_accuracy: 0.9524\n",
      "Epoch 72/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3052 - accuracy: 0.8810 - val_loss: 0.4006 - val_accuracy: 0.8095\n",
      "Epoch 73/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3077 - accuracy: 0.8690 - val_loss: 0.3815 - val_accuracy: 0.9048\n",
      "Epoch 74/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2854 - accuracy: 0.8571 - val_loss: 0.3683 - val_accuracy: 0.9048\n",
      "Epoch 75/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3206 - accuracy: 0.8214 - val_loss: 0.3812 - val_accuracy: 0.8571\n",
      "Epoch 76/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3269 - accuracy: 0.8571 - val_loss: 0.3650 - val_accuracy: 0.9524\n",
      "Epoch 77/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3168 - accuracy: 0.8452 - val_loss: 0.3721 - val_accuracy: 0.8571\n",
      "Epoch 78/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2796 - accuracy: 0.9405 - val_loss: 0.3573 - val_accuracy: 0.9048\n",
      "Epoch 79/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2569 - accuracy: 0.9048 - val_loss: 0.3560 - val_accuracy: 0.9048\n",
      "Epoch 80/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3005 - accuracy: 0.8571 - val_loss: 0.3552 - val_accuracy: 0.9048\n",
      "Epoch 81/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2959 - accuracy: 0.9048 - val_loss: 0.3607 - val_accuracy: 0.9048\n",
      "Epoch 82/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2939 - accuracy: 0.8810 - val_loss: 0.3633 - val_accuracy: 0.8571\n",
      "Epoch 83/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.3458 - accuracy: 0.8333 - val_loss: 0.3411 - val_accuracy: 0.9048\n",
      "Epoch 84/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2510 - accuracy: 0.9048 - val_loss: 0.3347 - val_accuracy: 0.9048\n",
      "Epoch 85/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2407 - accuracy: 0.8929 - val_loss: 0.3658 - val_accuracy: 0.8571\n",
      "Epoch 86/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2628 - accuracy: 0.8690 - val_loss: 0.3356 - val_accuracy: 0.9048\n",
      "Epoch 87/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2664 - accuracy: 0.8810 - val_loss: 0.3358 - val_accuracy: 0.9048\n",
      "Epoch 88/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2541 - accuracy: 0.8810 - val_loss: 0.3272 - val_accuracy: 0.9048\n",
      "Epoch 89/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.1954 - accuracy: 0.9524 - val_loss: 0.3194 - val_accuracy: 0.9524\n",
      "Epoch 90/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3357 - accuracy: 0.8333 - val_loss: 0.3301 - val_accuracy: 0.9048\n",
      "Epoch 91/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2876 - accuracy: 0.8929 - val_loss: 0.3363 - val_accuracy: 0.9048\n",
      "Epoch 92/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2041 - accuracy: 0.9048 - val_loss: 0.3142 - val_accuracy: 0.9048\n",
      "Epoch 93/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2769 - accuracy: 0.8690 - val_loss: 0.3169 - val_accuracy: 0.9048\n",
      "Epoch 94/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.3105 - accuracy: 0.8690 - val_loss: 0.3163 - val_accuracy: 0.9048\n",
      "Epoch 95/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2730 - accuracy: 0.8929 - val_loss: 0.3269 - val_accuracy: 0.9048\n",
      "Epoch 96/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2670 - accuracy: 0.8929 - val_loss: 0.3155 - val_accuracy: 0.9048\n",
      "Epoch 97/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2480 - accuracy: 0.8690 - val_loss: 0.3175 - val_accuracy: 0.9048\n",
      "Epoch 98/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2166 - accuracy: 0.9048 - val_loss: 0.3059 - val_accuracy: 0.9048\n",
      "Epoch 99/100\n",
      "84/84 [==============================] - 0s 1ms/sample - loss: 0.2532 - accuracy: 0.8929 - val_loss: 0.3075 - val_accuracy: 0.9048\n",
      "Epoch 100/100\n",
      "84/84 [==============================] - 0s 2ms/sample - loss: 0.2855 - accuracy: 0.8690 - val_loss: 0.3085 - val_accuracy: 0.9048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6d341507b8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=4)\n",
    "model_keras = Sequential()\n",
    "\n",
    "# Define the first layer\n",
    "model_keras.add(keras.layers.Dense(36, activation='relu', input_shape = (4,)))\n",
    "model_keras.add(keras.layers.Dropout(0.2))\n",
    "# Add activation function to classifier\n",
    "model_keras.add(keras.layers.Dense(18, activation='relu'))\n",
    "model_keras.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model_keras.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "# Finish the model compilation\n",
    "model_keras.compile(optimizer = keras.optimizers.Adam(lr=0.001), \n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Complete the model fit operation\n",
    "model_keras.fit(X_train, Y_train_cat, epochs=100, batch_size=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99464188e+01, 5.30442744e-02, 5.41410001e-04],\n",
       "       [4.21132369e-04, 6.68173075e+00, 9.33178406e+01],\n",
       "       [1.10351217e+00, 8.39637222e+01, 1.49327650e+01],\n",
       "       [9.99404678e+01, 5.89883812e-02, 5.51799138e-04],\n",
       "       [8.94840336e+00, 8.37659378e+01, 7.28566122e+00],\n",
       "       [1.14879525e+00, 8.17597122e+01, 1.70914955e+01],\n",
       "       [9.99308472e+01, 6.84410334e-02, 7.11312867e-04],\n",
       "       [1.94535556e-03, 8.68579102e+00, 9.13122559e+01],\n",
       "       [9.99805527e+01, 1.93334036e-02, 1.13407274e-04],\n",
       "       [3.45327187e+00, 8.27137604e+01, 1.38329611e+01],\n",
       "       [2.81254615e-04, 5.16922903e+00, 9.48304825e+01],\n",
       "       [1.03634381e+00, 8.24807816e+01, 1.64828796e+01],\n",
       "       [9.99800491e+01, 1.98325757e-02, 1.18446602e-04],\n",
       "       [9.99711838e+01, 2.86232308e-02, 1.92248102e-04],\n",
       "       [2.83905625e-01, 7.35716858e+01, 2.61444092e+01],\n",
       "       [9.99567184e+01, 4.28698622e-02, 4.08424472e-04],\n",
       "       [6.30705178e-01, 8.40075378e+01, 1.53617573e+01],\n",
       "       [8.13218685e-06, 1.83692575e+00, 9.81630630e+01],\n",
       "       [1.03060994e-03, 8.80340672e+00, 9.11955566e+01],\n",
       "       [1.23632386e-01, 4.96898651e+01, 5.01865044e+01],\n",
       "       [9.99966965e+01, 3.29251913e-03, 6.81450274e-06],\n",
       "       [2.50115812e-01, 6.94288635e+01, 3.03210258e+01],\n",
       "       [9.99183807e+01, 8.06661472e-02, 9.52023489e-04],\n",
       "       [1.94535556e-03, 8.68579102e+00, 9.13122559e+01],\n",
       "       [8.91852134e-04, 8.83642673e+00, 9.11626892e+01],\n",
       "       [5.14447510e-01, 7.90693436e+01, 2.04162083e+01],\n",
       "       [2.70736404e-03, 1.28456964e+01, 8.71515961e+01],\n",
       "       [4.62128490e-01, 8.33035736e+01, 1.62342987e+01],\n",
       "       [1.79348790e-04, 4.69350004e+00, 9.53063278e+01],\n",
       "       [9.99598236e+01, 3.98300141e-02, 3.40065104e-04],\n",
       "       [9.99343185e+01, 6.49935305e-02, 6.76137395e-04],\n",
       "       [9.99441833e+01, 5.53289317e-02, 4.85414639e-04],\n",
       "       [2.61602551e-01, 7.52270203e+01, 2.45113811e+01],\n",
       "       [9.99461594e+01, 5.33053465e-02, 5.39912726e-04],\n",
       "       [9.99813004e+01, 1.85880158e-02, 1.08272594e-04],\n",
       "       [9.99521637e+01, 4.74110693e-02, 4.28183237e-04],\n",
       "       [2.53563776e-04, 5.85523558e+00, 9.41445084e+01],\n",
       "       [9.99780121e+01, 2.18596011e-02, 1.28158877e-04],\n",
       "       [9.99657364e+01, 3.40429246e-02, 2.18746412e-04],\n",
       "       [3.89793180e-02, 3.58199730e+01, 6.41410446e+01],\n",
       "       [3.17045003e-02, 3.32970963e+01, 6.66711960e+01],\n",
       "       [9.99156036e+01, 8.34716931e-02, 9.26998036e-04],\n",
       "       [9.99754486e+01, 2.43992470e-02, 1.50644308e-04],\n",
       "       [1.18578831e-03, 1.20139065e+01, 8.79849091e+01],\n",
       "       [4.30105312e-04, 7.75809383e+00, 9.22414780e+01],\n",
       "       [1.48750166e-03, 7.38741064e+00, 9.26111069e+01],\n",
       "       [9.98953094e+01, 1.03412151e-01, 1.27692928e-03],\n",
       "       [4.53817558e+00, 8.78591919e+01, 7.60263968e+00],\n",
       "       [3.27189133e-04, 5.80639029e+00, 9.41932831e+01],\n",
       "       [9.99780960e+01, 2.17773877e-02, 1.33238966e-04],\n",
       "       [9.99423065e+01, 5.71799241e-02, 5.23237279e-04],\n",
       "       [2.70639756e-03, 9.85566711e+00, 9.01416321e+01],\n",
       "       [4.35701746e-04, 5.62467480e+00, 9.43748856e+01],\n",
       "       [9.99959335e+01, 4.04754374e-03, 1.06171010e-05],\n",
       "       [1.50502324e+00, 8.66949234e+01, 1.18000536e+01],\n",
       "       [9.99865875e+01, 1.33553203e-02, 5.73352663e-05],\n",
       "       [8.61245021e-03, 1.26359177e+01, 8.73554688e+01],\n",
       "       [1.83396798e-04, 6.92888594e+00, 9.30709381e+01],\n",
       "       [9.99260025e+01, 7.31210783e-02, 8.85570829e-04],\n",
       "       [8.53651611e-04, 7.57780838e+00, 9.24213409e+01],\n",
       "       [3.06539744e-01, 7.65850067e+01, 2.31084538e+01],\n",
       "       [2.43037105e-01, 7.99525681e+01, 1.98044052e+01],\n",
       "       [1.39553088e-03, 1.07948170e+01, 8.92037888e+01],\n",
       "       [9.99680023e+01, 3.17720063e-02, 2.30586986e-04],\n",
       "       [5.67532750e-03, 1.99591331e+01, 8.00351868e+01],\n",
       "       [9.99787903e+01, 2.10979152e-02, 1.19610660e-04],\n",
       "       [8.22331548e-01, 7.99944992e+01, 1.91831646e+01],\n",
       "       [1.74745414e-02, 2.88197346e+01, 7.11627884e+01],\n",
       "       [9.99888763e+01, 1.10738613e-02, 4.28056919e-05],\n",
       "       [8.96238148e-01, 8.27799835e+01, 1.63237801e+01],\n",
       "       [9.98886261e+01, 1.09825216e-01, 1.54926896e-03],\n",
       "       [6.35406759e-04, 6.98242712e+00, 9.30169373e+01],\n",
       "       [1.82853147e-01, 6.76601944e+01, 3.21569519e+01],\n",
       "       [4.89720369e-05, 3.41912293e+00, 9.65808258e+01],\n",
       "       [9.99797897e+01, 2.00966764e-02, 1.15966068e-04],\n",
       "       [5.96913218e-04, 7.21259117e+00, 9.27868118e+01],\n",
       "       [1.64454148e-04, 5.15576601e+00, 9.48440704e+01],\n",
       "       [6.29284047e-03, 1.57659378e+01, 8.42277679e+01],\n",
       "       [2.11850092e-01, 7.67309341e+01, 2.30572071e+01],\n",
       "       [9.99869080e+01, 1.30233997e-02, 5.82264147e-05],\n",
       "       [9.99831238e+01, 1.67765152e-02, 9.42108018e-05],\n",
       "       [3.94831644e-03, 1.11971979e+01, 8.87988510e+01],\n",
       "       [1.99695677e-02, 2.80666046e+01, 7.19134216e+01],\n",
       "       [9.99555969e+01, 4.40218560e-02, 3.86372674e-04],\n",
       "       [7.00307548e-01, 7.22839203e+01, 2.70157719e+01],\n",
       "       [2.51606293e-03, 2.55015812e+01, 7.44959030e+01],\n",
       "       [3.07298219e-03, 1.31869078e+01, 8.68100128e+01],\n",
       "       [1.73078419e-03, 9.47987843e+00, 9.05183945e+01],\n",
       "       [4.97966958e-03, 1.39469738e+01, 8.60480423e+01],\n",
       "       [9.99695663e+01, 3.02263629e-02, 2.11977516e-04],\n",
       "       [1.82514731e-02, 3.18916473e+01, 6.80901031e+01],\n",
       "       [9.99825058e+01, 1.73993837e-02, 9.40367972e-05],\n",
       "       [2.36248504e-02, 3.46461716e+01, 6.53302002e+01],\n",
       "       [1.22694027e+00, 7.55701065e+01, 2.32029533e+01],\n",
       "       [4.80212271e-03, 1.61006355e+01, 8.38945618e+01],\n",
       "       [3.77057935e-04, 5.30966473e+00, 9.46899567e+01],\n",
       "       [9.99795151e+01, 2.03684103e-02, 1.22384285e-04],\n",
       "       [2.64876219e-03, 1.29603882e+01, 8.70369644e+01],\n",
       "       [8.43161881e-01, 8.70038834e+01, 1.21529531e+01],\n",
       "       [2.29185894e-01, 6.81802216e+01, 3.15905933e+01],\n",
       "       [1.52231276e-01, 6.38599167e+01, 3.59878464e+01],\n",
       "       [5.85451536e-02, 4.30170517e+01, 5.69244041e+01],\n",
       "       [1.81501186e+00, 8.38854218e+01, 1.42995653e+01],\n",
       "       [9.99496231e+01, 4.99097928e-02, 4.64673882e-04],\n",
       "       [9.24785733e-01, 8.20695801e+01, 1.70056324e+01]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.array(model_keras.predict(X_train))\n",
    "\n",
    "predictions*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
