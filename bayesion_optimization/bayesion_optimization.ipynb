{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import catboost as cgb\n",
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load Boston housing data\n",
    "boston=load_boston()\n",
    "X = pd.DataFrame(boston.data,columns=boston.feature_names)\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | max_depth | min_ch... | min_sp... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8621  \u001b[0m | \u001b[0m 0.9838  \u001b[0m | \u001b[0m 0.6138  \u001b[0m | \u001b[0m 23.03   \u001b[0m | \u001b[0m 12.09   \u001b[0m | \u001b[0m 0.009645\u001b[0m | \u001b[0m 95.76   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8639  \u001b[0m | \u001b[95m 0.8652  \u001b[0m | \u001b[95m 0.5329  \u001b[0m | \u001b[95m 18.92   \u001b[0m | \u001b[95m 18.18   \u001b[0m | \u001b[95m 0.04065 \u001b[0m | \u001b[95m 94.3    \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.864   \u001b[0m | \u001b[95m 0.9673  \u001b[0m | \u001b[95m 0.5708  \u001b[0m | \u001b[95m 19.37   \u001b[0m | \u001b[95m 14.22   \u001b[0m | \u001b[95m 0.07085 \u001b[0m | \u001b[95m 88.45   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8597  \u001b[0m | \u001b[0m 0.8115  \u001b[0m | \u001b[0m 0.6976  \u001b[0m | \u001b[0m 20.62   \u001b[0m | \u001b[0m 12.64   \u001b[0m | \u001b[0m 0.005888\u001b[0m | \u001b[0m 85.85   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8608  \u001b[0m | \u001b[0m 0.8134  \u001b[0m | \u001b[0m 0.7009  \u001b[0m | \u001b[0m 17.51   \u001b[0m | \u001b[0m 16.48   \u001b[0m | \u001b[0m 0.03705 \u001b[0m | \u001b[0m 83.04   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8535  \u001b[0m | \u001b[0m 0.9292  \u001b[0m | \u001b[0m 0.8359  \u001b[0m | \u001b[0m 24.69   \u001b[0m | \u001b[0m 24.92   \u001b[0m | \u001b[0m 0.03928 \u001b[0m | \u001b[0m 99.99   \u001b[0m |\n"
     ]
    }
   ],
   "source": [
    "def bayesion_opt_lgbm(X, y, init_iter=3, n_iters=7, random_state=11, seed = 101, num_iterations = 100):\n",
    "    dtrain = lgb.Dataset(data=X, label=y)\n",
    "    def lgb_r2_score(preds, dtrain):\n",
    "        labels = dtrain.get_label()\n",
    "        return 'r2', r2_score(labels, preds), True\n",
    "  # Objective Function\n",
    "    def hyp_lgbm(num_leaves, feature_fraction, bagging_fraction, max_depth, min_split_gain, min_child_weight):\n",
    "        params = {'application':'regression','num_iterations': num_iterations,\n",
    "                    'learning_rate':0.05, 'early_stopping_round':50,\n",
    "                    'metric':'lgb_r2_score'} # Default parameters\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        params['max_depth'] = int(round(max_depth))\n",
    "        params['min_split_gain'] = min_split_gain\n",
    "        params['min_child_weight'] = min_child_weight\n",
    "        cv_results = lgb.cv(params, dtrain, nfold=5, seed=seed,categorical_feature=[], stratified=False,\n",
    "                              verbose_eval =None, feval=lgb_r2_score)\n",
    "          # print(cv_results)\n",
    "        return np.max(cv_results['r2-mean'])\n",
    "  # Domain space-- Range of hyperparameters \n",
    "    pds = {'num_leaves': (80, 100),\n",
    "            'feature_fraction': (0.1, 0.9),\n",
    "            'bagging_fraction': (0.8, 1),\n",
    "            'max_depth': (17, 25),\n",
    "            'min_split_gain': (0.001, 0.1),\n",
    "            'min_child_weight': (10, 25)\n",
    "            }\n",
    "\n",
    "  # Surrogate model\n",
    "    optimizer = BayesianOptimization(hyp_lgbm, pds, random_state=random_state)\n",
    "                                    \n",
    "  # Optimize\n",
    "    optimizer.maximize(init_points=init_iter, n_iter=n_iters)\n",
    "    obtimizer.max['params']\n",
    "bayesion_opt_lgbm(X, y, init_iter=5, n_iters=10, random_state=77, seed = 101, num_iterations = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
