{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import catboost as cgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "import warnings\n",
    "import wandb\n",
    "import time\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "METHOD = 'bayes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features=[i for i in X.columns if X.dtypes[i]!='float']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('house_prices_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 127)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('SalePrice',axis =1)\n",
    "\n",
    "y = data['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X,y,test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error, mean_absolute_error, r2_score\n",
    "\n",
    "def rmsle(y_test, y_preds):\n",
    "    \"\"\"\n",
    "    Calculates Root Mean Squared Log Error between predictions and true labels\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_log_error(y_test,y_preds))\n",
    "\n",
    "def rmse(predictions, targets): \n",
    "\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "def rmsle2(y, y0):\n",
    "    return np.sqrt(np.mean(np.square(np.log1p(y) - np.log1p(y0))))\n",
    "\n",
    "# Create function to evaluate model on a few different levels\n",
    "def show_scores(model):\n",
    "    train_preds = model.predict(X_train)\n",
    "    val_preds = model.predict(X_test)\n",
    "    scores = {'Training MAE': mean_absolute_error(y_train,train_preds),\n",
    "             'Valid MAE': mean_absolute_error(y_test,val_preds),\n",
    "             'Training R^2': r2_score(y_train,train_preds),\n",
    "             'Valid R^2': r2_score(y_test,val_preds),\n",
    "             'Training RMSE': rmse(y_train,train_preds),\n",
    "             'Valid RMSE': rmse(y_test,val_preds),\n",
    "             'Training RMSLE2': rmsle2(y_train,train_preds),\n",
    "             'Valid RMSLE2': rmsle2(y_test,val_preds)\n",
    "             }\n",
    "    \n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Prepare data tuples\n",
    "    (X_train, y_train) = X_train1, y_train1\n",
    "    (X_test, y_test) = X_test1, y_test1\n",
    "    \n",
    "    # Default values for hyper-parameters we're going to sweep over\n",
    "    configs = {\n",
    "            'num_leaves': 100,            \n",
    "            'feature_fraction': 0.1,\n",
    "            'bagging_fraction': 0.1,\n",
    "            'max_depth': 200,\n",
    "            'min_split_gain': 0.001,\n",
    "            'min_child_weight': 1,\n",
    "            'method': METHOD\n",
    "    }\n",
    "\n",
    "    # Initilize a new wandb run\n",
    "    wandb.init(project='hyperparameter-sweeps-lgb', config=configs)\n",
    "    \n",
    "    # Config is a variable that holds and saves hyperparameters and inputs\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Define the model\n",
    "    clf = lgb.LGBMRegressor(bagging_fraction = configs.bagging_fraction,\n",
    "                       feature_fraction = configs.feature_fraction,\n",
    "                       max_depth = configs.max_depth,\n",
    "                       min_child_weight = configs.min_child_weight,\n",
    "                       min_split_gain = configs.min_split_gain,\n",
    "                       num_leaves = configs.num_leaves)\n",
    "    \n",
    "    # Train the model\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sweep_id(method):\n",
    "    sweep_config = {\n",
    "        'method': method,\n",
    "        'metric': {\n",
    "          'name': 'rmse',\n",
    "          'goal': 'minimize'   \n",
    "        },\n",
    "        'parameters':{\n",
    "            'num_leaves':{\n",
    "                'values': (100, 700)\n",
    "            },\n",
    "            'feature_fraction':{ 'values': (0.1, 0.9)},\n",
    "            'bagging_fraction':{ 'values': (0.1, 1)},\n",
    "            'max_depth':{ 'values': (200, 500)},\n",
    "            'min_split_gain':{ 'values': (0.001, 0.1)},\n",
    "            'min_child_weight': {'values': (1, 100) }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    sweep_id = wandb.sweep(sweep_config, project='hyperparameter-sweeps-comparison')\n",
    "    \n",
    "    return sweep_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 5patsapr\n",
      "Sweep URL: https://app.wandb.ai/sinisha123/hyperparameter-sweeps-comparison/sweeps/5patsapr\n"
     ]
    }
   ],
   "source": [
    "sweep_id = get_sweep_id('bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 9xo0keox with config:\n",
      "\tbagging_fraction: 1\n",
      "\tfeature_fraction: 0.1\n",
      "\tmax_depth: 500\n",
      "\tmin_child_weight: 1\n",
      "\tmin_split_gain: 0.001\n",
      "\tnum_leaves: 700\n",
      "wandb: Agent Started Run: 9xo0keox\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Ignoring project='hyperparameter-sweeps-lgb' passed to wandb.init when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/sinisha123/hyperparameter-sweeps-comparison\" target=\"_blank\">https://app.wandb.ai/sinisha123/hyperparameter-sweeps-comparison</a><br/>\n",
       "                Sweep page: <a href=\"https://app.wandb.ai/sinisha123/hyperparameter-sweeps-comparison/sweeps/5patsapr\" target=\"_blank\">https://app.wandb.ai/sinisha123/hyperparameter-sweeps-comparison/sweeps/5patsapr</a><br/>\n",
       "Run page: <a href=\"https://app.wandb.ai/sinisha123/hyperparameter-sweeps-comparison/runs/9xo0keox\" target=\"_blank\">https://app.wandb.ai/sinisha123/hyperparameter-sweeps-comparison/runs/9xo0keox</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sinisha/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sinisha/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sinisha/miniconda3/lib/python3.6/site-packages/wandb/wandb_agent.py\", line 64, in _start\n",
      "    function()\n",
      "  File \"<ipython-input-22-24b6c6bdc2b3>\", line 24, in train\n",
      "    clf = lgb.LGBMRegressor(bagging_fraction = configs.bagging_fraction,\n",
      "AttributeError: 'dict' object has no attribute 'bagging_fraction'\n",
      "wandb: Ctrl-c pressed. Waiting for runs to end. Press ctrl-c again to terminate them.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
